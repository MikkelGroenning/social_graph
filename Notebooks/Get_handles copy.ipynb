{
 "cells": [
  {
   "source": [
    "Import packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import camelot\n",
    "import tweepy\n",
    "from src.tools.twitter_api import auth"
   ]
  },
  {
   "source": [
    "### 116<sup>th</sup> congress\n",
    "\n",
    "First the twitter handles for the 116<sup>th</sup> congress will be extracted using [this](https://triagecancer.org/congressional-social-media) source. The choice of source comes from the fact that the Twitter handle as well as the party is desired.\n",
    "\n",
    "`BeautifulSoup` is used to extract the HTML table from the webpage (that has been downloaded to allow for offline work)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data\n",
    "with open('../Data/Raw/116_congress_twitter.html') as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "# Find table\n",
    "table = soup.find('table', attrs={'id':\"footable_16836\"})\n",
    "\n",
    "# Extract data row wise from table\n",
    "l = []\n",
    "for tr in table.findAll('tr'):\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "\n",
    "# Make the data into a Pandas data frame and drop irrelevant columns\n",
    "Data116 = pd.DataFrame(l[1:], columns = [header.getText() for header in table.findAll('th')]).drop(columns = ['Name Links', 'Twitter Links', 'Instagram', 'Facebook Page', 'Facebook'])\n",
    "\n",
    "# Ensure that the type of politician is alligned\n",
    "rename_chamber = {'U.S. Representative': 'Representative', 'U.S. Senator': 'Senator'}\n",
    "Data116 = Data116.replace(rename_chamber).rename(columns = {'Chamber of Congress': 'Type'})"
   ]
  },
  {
   "source": [
    "In this data set the state is given as well as congressional district. This is fixed using regex strings as shown below. Moreover the \"@\" are removed from the Twitter handles as the Twitter API does not need it. The vancant positions in Congress are also disregarded."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    State            Type             Name Party          Twitter\n0      AL         Senator   Richard Shelby     R        SenShelby\n1      AL         Senator       Doug Jones     D        DougJones\n2      AL  Representative   Byrne, Bradley     R         RepByrne\n3      AL  Representative     Roby, Martha     R    RepMarthaRoby\n4      AL  Representative     Rogers, Mike     R  RepMikeRogersAL\n..    ...             ...              ...   ...              ...\n536    WI  Representative  Tiffany, Thomas     R     TomTiffanyWI\n537    WI  Representative  Gallagher, Mike     R        MikeforWI\n538    WY         Senator       Enzi, Mike     R      SenatorEnzi\n539    WY         Senator   Barrasso, John     R  SenJohnBarrasso\n540    WY  Representative      Cheney, Liz     R       Liz_Cheney\n\n[537 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>State</th>\n      <th>Type</th>\n      <th>Name</th>\n      <th>Party</th>\n      <th>Twitter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AL</td>\n      <td>Senator</td>\n      <td>Richard Shelby</td>\n      <td>R</td>\n      <td>SenShelby</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AL</td>\n      <td>Senator</td>\n      <td>Doug Jones</td>\n      <td>D</td>\n      <td>DougJones</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AL</td>\n      <td>Representative</td>\n      <td>Byrne, Bradley</td>\n      <td>R</td>\n      <td>RepByrne</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AL</td>\n      <td>Representative</td>\n      <td>Roby, Martha</td>\n      <td>R</td>\n      <td>RepMarthaRoby</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AL</td>\n      <td>Representative</td>\n      <td>Rogers, Mike</td>\n      <td>R</td>\n      <td>RepMikeRogersAL</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>536</th>\n      <td>WI</td>\n      <td>Representative</td>\n      <td>Tiffany, Thomas</td>\n      <td>R</td>\n      <td>TomTiffanyWI</td>\n    </tr>\n    <tr>\n      <th>537</th>\n      <td>WI</td>\n      <td>Representative</td>\n      <td>Gallagher, Mike</td>\n      <td>R</td>\n      <td>MikeforWI</td>\n    </tr>\n    <tr>\n      <th>538</th>\n      <td>WY</td>\n      <td>Senator</td>\n      <td>Enzi, Mike</td>\n      <td>R</td>\n      <td>SenatorEnzi</td>\n    </tr>\n    <tr>\n      <th>539</th>\n      <td>WY</td>\n      <td>Senator</td>\n      <td>Barrasso, John</td>\n      <td>R</td>\n      <td>SenJohnBarrasso</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>WY</td>\n      <td>Representative</td>\n      <td>Cheney, Liz</td>\n      <td>R</td>\n      <td>Liz_Cheney</td>\n    </tr>\n  </tbody>\n</table>\n<p>537 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# All states abbreviations\n",
    "us_state_abbrev = {\n",
    "    r'Alabama.*': 'AL',\n",
    "    r'Alaska.*': 'AK',\n",
    "    r'American Samoa.*': 'AS',\n",
    "    r'Arizona.*': 'AZ',\n",
    "    r'Arkansas.*': 'AR',\n",
    "    r'California.*': 'CA',\n",
    "    r'Colorado.*': 'CO',\n",
    "    r'Connecticut.*': 'CT',\n",
    "    r'Delaware.*': 'DE',\n",
    "    r'District of Columbia.*': 'DC',\n",
    "    r'Florida.*': 'FL',\n",
    "    r'Georgia.*': 'GA',\n",
    "    r'Guam.*': 'GU',\n",
    "    r'Hawaii.*': 'HI',\n",
    "    r'Idaho.*': 'ID',\n",
    "    r'Illinois.*': 'IL',\n",
    "    r'Indiana.*': 'IN',\n",
    "    r'Iowa.*': 'IA',\n",
    "    r'Kansas.*': 'KS',\n",
    "    r'Kentucky.*': 'KY',\n",
    "    r'Louisiana.*': 'LA',\n",
    "    r'Maine.*': 'ME',\n",
    "    r'Maryland.*': 'MD',\n",
    "    r'Massachusetts.*': 'MA',\n",
    "    r'Michigan.*': 'MI',\n",
    "    r'Minnesota.*': 'MN',\n",
    "    r'Mississippi.*': 'MS',\n",
    "    r'Missouri.*': 'MO',\n",
    "    r'Montana.*': 'MT',\n",
    "    r'Nebraska.*': 'NE',\n",
    "    r'Nevada.*': 'NV',\n",
    "    r'New Hampshire.*': 'NH',\n",
    "    r'New Jersey.*': 'NJ',\n",
    "    r'New Mexico.*': 'NM',\n",
    "    r'New York.*': 'NY',\n",
    "    r'North Carolina.*': 'NC',\n",
    "    r'North Dakota.*': 'ND',\n",
    "    r'Northern Mariana Islands.*':'MP',\n",
    "    r'Ohio.*': 'OH',\n",
    "    r'Oklahoma.*': 'OK',\n",
    "    r'Oregon.*': 'OR',\n",
    "    r'Pennsylvania.*': 'PA',\n",
    "    r'Puerto Rico.*': 'PR',\n",
    "    r'Rhode Island.*': 'RI',\n",
    "    r'South Carolina.*': 'SC',\n",
    "    r'South Dakota.*': 'SD',\n",
    "    r'Tennessee.*': 'TN',\n",
    "    r'Texas.*': 'TX',\n",
    "    r'Utah.*': 'UT',\n",
    "    r'Vermont.*': 'VT',\n",
    "    r'Virgin Islands.*': 'VI',\n",
    "    r'Virginia.*': 'VA',\n",
    "    r'Washington.*': 'WA',\n",
    "    r'West V.*': 'WV', # Written in different ways\n",
    "    r'Wisconsin.*': 'WI',\n",
    "    r'Wyoming.*': 'WY'\n",
    "}\n",
    "\n",
    "# Convert states to two letter abbreviations\n",
    "Data116 = Data116.replace(regex = us_state_abbrev)\n",
    "\n",
    "# Remove @\n",
    "Data116 = Data116.replace(regex = {r'^@': ''})\n",
    "\n",
    "# Remove vacant positions\n",
    "Data116 = Data116[Data116.Name != \"Vacant\"]\n",
    "\n",
    "# Look at the data\n",
    "Data116"
   ]
  },
  {
   "source": [
    "It is also seen that there are an inconsistency in the ways the names are written. This is changed so all names are written with the first name first:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data116['Name'] = [name[1][1:]+ \" \" +name[0] if len(name) == 2 else name[0] for name in [name.replace(u'\\xa0', u'').split(',') for name in Data116.Name]]"
   ]
  },
  {
   "source": [
    "### 115<sup>th</sup> congress\n",
    "\n",
    "Now we move onto the 115th congress. This is data stored in a pdf.table, so for this the `camelot` library is used. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Please make sure that Ghostscript is installed",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/ext/ghostscript/_gsprint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mlibgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libgs.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(libgs.so, 6): image not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cf41f9331c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read table across all pages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamelot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile115\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert data to pandas data frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/io.py\u001b[0m in \u001b[0;36mread_pdf\u001b[0;34m(filepath, pages, password, flavor, suppress_stdout, layout_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0msuppress_stdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_stdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mlayout_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/handlers.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, flavor, suppress_stdout, layout_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 t = parser.extract_tables(\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_stdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_stdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayout_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m                 \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/parsers/lattice.py\u001b[0m in \u001b[0;36mextract_tables\u001b[0;34m(self, filename, suppress_stdout, layout_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_table_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/parsers/lattice.py\u001b[0m in \u001b[0;36m_generate_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_generate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mghostscript\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGhostscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrootname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/ext/ghostscript/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_gsprint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/social_graphs_project/lib/python3.7/site-packages/camelot/ext/ghostscript/_gsprint.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mlibgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlibgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please make sure that Ghostscript is installed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mlibgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Please make sure that Ghostscript is installed"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "file115 = '../Data/Raw/115_congress_twitter.pdf'\n",
    "\n",
    "# Read table across all pages\n",
    "tables = camelot.read_pdf(file115, pages = 'all')\n",
    "\n",
    "# Convert data to pandas data frame\n",
    "Data115 = pd.DataFrame(np.concatenate([d.df.drop(0).values for d in tables]), columns=tables[0].df.iloc[0]).drop(columns = \"District\")\n",
    "\n",
    "# Align chamber name with the 116 data\n",
    "rename_chamber = {'Rep.': 'Representative', 'Sen.': 'Senator'}\n",
    "Data115 = Data115.replace(rename_chamber)\n",
    "\n",
    "# Align name with the 116 data and store it in one column\n",
    "Data115[\"Name\"] = Data115[\"First Name\"] + \" \" + Data115[\"Last Name\"]\n",
    "Data115 = Data115.drop(columns = [\"First Name\", \"Last Name\"])\n",
    "\n",
    "# Align columns name with the 116 data\n",
    "Data115 = Data115.rename(columns = {'Title': 'Type', \"Twitter Handle\": \"Twitter\"})"
   ]
  },
  {
   "source": [
    "### Merge data\n",
    "\n",
    "Now the two datasets are merged. Here we need to take duplicate acounts into account which accounts for reelections."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data set\n",
    "Data_Full = Data115.append(Data116, ignore_index = True)\n",
    "\n",
    "# Get shape\n",
    "Data_Full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "to_remove = []\n",
    "twitter_display_name = []\n",
    "for index, handle in enumerate(Data_Full.Twitter):\n",
    "    try:\n",
    "        u=api.get_user(handle)\n",
    "        twitter_display_name.append(u.name)\n",
    "    except Exception:\n",
    "        to_remove.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop(index=to_remove)\n",
    "Data_Full['twitter_display_name'] = twitter_display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Twitter\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Name\"], keep = 'last')"
   ]
  },
  {
   "source": [
    "Add the President"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.append({'State': None, 'Party': 'R', 'Type': 'POTUS', 'Twitter': 'realDonaldTrump', 'Name': 'Donald J. Trump'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full"
   ]
  },
  {
   "source": [
    "## Get the display Twitter Name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full.to_csv('../Data/Processed/Twitter_Handles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitsocialgraphsprojectconda9e1414738f16463880d93a451ffa336f",
   "display_name": "Python 3.7.9 64-bit ('social_graphs_project': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}