{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('social_graphs_project': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6546ecbd99b842a99621f65df02378b87ae0c75bd44cf185fb02078db3b8f3b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Political Polarization in the US\n",
    "\n",
    "\n",
    "### By Toke Bøgelund Andersen (s164202), Mikkel Grønning (s144968) and Ida Riis Jensen (s161777)\n",
    "\n",
    "#### Course 02805 Social Graphs and Interactions "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src=\"https://img.youtube.com/vi/KEkrWRHCDQU/0.jpg\" alt=\"image info\" />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import camelot\n",
    "import tweepy\n",
    "import tqdm\n",
    "import networkx as nx \n",
    "import pickle\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from svgpathtools import svg2paths\n",
    "from svgpath2mpl import parse_path\n",
    "import matplotlib as mpl\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from fa2 import ForceAtlas2\n",
    "from community import community_louvain\n",
    "import plotly.express as px"
   ]
  },
  {
   "source": [
    "## Motivation\n",
    "\n",
    "### What is your dataset?\n",
    "The idea is to analyze data from `Twitter` with focus on tweets from the American congress in the period 2017-2020 to get an understanding of the political polarization in the US. The data used in this project consists of tweets from 1072 congress members from the 115th and 116th congress respectively and the president of the United States, Donald J. Trump. Data is from Harvard Dataverse (insert ref.) and Trump Twitter Archive (insert ref.) and contains the following information:\n",
    "\n",
    "You can read all about how tweets were extracted in [this] notebook. Notice, that to extract all the tweets you need to have a Twitter developer account in order for accessing the Twitter API. Extracting all the raw data takes approx. 24 hours, however extracting the cleaned and processed data takes approx. 6-8 hours as there are many duplicates and unecessary duplicates in raw data. In this notebook we will only consider the cleaned data but again we refer to the other notebook for full elaboration on how data was extracted and cleaned. \n",
    "\n",
    "\n",
    "* The state they are from,\n",
    "* whether they are representative, senator or POTUS,\n",
    "* their full name,\n",
    "* which party they are member of,\n",
    "* and their Twitter handle. \n",
    "The Twitter handles have been used to download tweets from all members in the given period using the Twitter API (insert ref.). In addition, we have added 16 of the largest media in the US with same attributes but without tweets. \n",
    "\n",
    "Information about followers and retweets have been extracted for all users (both persons and medias) in order to create networks that might reveal some interesting information about the polarization.\n",
    "\n",
    "<img src=\"../figures/congress.png\" width=350 height=250 /> <img src=\"../figures/trumpeten.png\" width=350 height=250 /> <img src=\"../figures/medias.jpg\" width=350 height=250 />\n",
    "\n",
    "Per Twitter's Developer Policy, tweet ids may be publicy shared for academic purposes; tweets may not (insert ref.). Thus, the data available for our readers will not contain the tweets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Why did you choose these particular datasets?\n",
    "These particular datasets have been chosen as we want to investigate whether the political polarization in the US appears in the congress members tweets. One could suspect that the polarization was especially expressed during Donald Trump's presidency and therefore the period of his presidency is interesting to look at. It also guarantees us a large network which can be analysed based on both followers, retweets and a bipartite graph showing the polarization.\n",
    "\n",
    "In relation to text analysis, the language used on Twitter is allegedly not as neutral as the langugage used on Wikipedia which will result in a more interesting sentiment analysis. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### What was your goal for the end user's experience?\n",
    "\n",
    "The goal is to provide an analysis of whether the polarization of the political fronts is expressed in the form of tweets but also whether there exists a pattern in who follows and retweets each other internally in the congress. Additionally, the aim is also to provide insight into how the media influences this polarization. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Basic stats\n",
    "\n",
    "We are working with large datasets which demands a lot of cleansing and preprocessing. This section presents how data for the network part and the text analysis part of the assignment has been cleaned and processed. The steps are explained in this notebook and the corresponding notebooks and functions can be find on `GitHub` (insert ref.)\n",
    "\n",
    "<img src=\"../figures/data_processing.png\" width=660 height=150 />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Data cleaning and preprocessing\n",
    "\n",
    "#### 116<sup>th</sup> congress\n",
    "\n",
    "First the twitter handles for the 116<sup>th</sup> congress will be extracted using [this](https://triagecancer.org/congressional-social-media) source. The choice of source comes from the fact that the Twitter handle as well as the party is desired.\n",
    "\n",
    "`BeautifulSoup` is used to extract the HTML table from the webpage (that has been downloaded to allow for offline work)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data\n",
    "with open('../Data/Raw/116_congress_twitter.html') as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "# Find table\n",
    "table = soup.find('table', attrs={'id':\"footable_16836\"})\n",
    "\n",
    "# Extract data row wise from table\n",
    "l = []\n",
    "for tr in table.findAll('tr'):\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "\n",
    "# Make the data into a Pandas data frame and drop irrelevant columns\n",
    "Data116 = pd.DataFrame(l[1:], columns = [header.getText() for header in table.findAll('th')]).drop(columns = ['Name Links', 'Twitter Links', 'Instagram', 'Facebook Page', 'Facebook'])\n",
    "\n",
    "# Ensure that the type of politician is alligned\n",
    "rename_chamber = {'U.S. Representative': 'Representative', 'U.S. Senator': 'Senator'}\n",
    "Data116 = Data116.replace(rename_chamber).rename(columns = {'Chamber of Congress': 'Type'})"
   ]
  },
  {
   "source": [
    "In this data set the state is given as well as congressional district. This is fixed using regex strings as shown below. Moreover the \"@\" are removed from the Twitter handles as the Twitter API does not need it. The vancant positions in Congress are also disregarded."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All states abbreviations\n",
    "us_state_abbrev = {\n",
    "    r'Alabama.*': 'AL',\n",
    "    r'Alaska.*': 'AK',\n",
    "    r'American Samoa.*': 'AS',\n",
    "    r'Arizona.*': 'AZ',\n",
    "    r'Arkansas.*': 'AR',\n",
    "    r'California.*': 'CA',\n",
    "    r'Colorado.*': 'CO',\n",
    "    r'Connecticut.*': 'CT',\n",
    "    r'Delaware.*': 'DE',\n",
    "    r'District of Columbia.*': 'DC',\n",
    "    r'Florida.*': 'FL',\n",
    "    r'Georgia.*': 'GA',\n",
    "    r'Guam.*': 'GU',\n",
    "    r'Hawaii.*': 'HI',\n",
    "    r'Idaho.*': 'ID',\n",
    "    r'Illinois.*': 'IL',\n",
    "    r'Indiana.*': 'IN',\n",
    "    r'Iowa.*': 'IA',\n",
    "    r'Kansas.*': 'KS',\n",
    "    r'Kentucky.*': 'KY',\n",
    "    r'Louisiana.*': 'LA',\n",
    "    r'Maine.*': 'ME',\n",
    "    r'Maryland.*': 'MD',\n",
    "    r'Massachusetts.*': 'MA',\n",
    "    r'Michigan.*': 'MI',\n",
    "    r'Minnesota.*': 'MN',\n",
    "    r'Mississippi.*': 'MS',\n",
    "    r'Missouri.*': 'MO',\n",
    "    r'Montana.*': 'MT',\n",
    "    r'Nebraska.*': 'NE',\n",
    "    r'Nevada.*': 'NV',\n",
    "    r'New Hampshire.*': 'NH',\n",
    "    r'New Jersey.*': 'NJ',\n",
    "    r'New Mexico.*': 'NM',\n",
    "    r'New York.*': 'NY',\n",
    "    r'North Carolina.*': 'NC',\n",
    "    r'North Dakota.*': 'ND',\n",
    "    r'Northern Mariana Islands.*':'MP',\n",
    "    r'Ohio.*': 'OH',\n",
    "    r'Oklahoma.*': 'OK',\n",
    "    r'Oregon.*': 'OR',\n",
    "    r'Pennsylvania.*': 'PA',\n",
    "    r'Puerto Rico.*': 'PR',\n",
    "    r'Rhode Island.*': 'RI',\n",
    "    r'South Carolina.*': 'SC',\n",
    "    r'South Dakota.*': 'SD',\n",
    "    r'Tennessee.*': 'TN',\n",
    "    r'Texas.*': 'TX',\n",
    "    r'Utah.*': 'UT',\n",
    "    r'Vermont.*': 'VT',\n",
    "    r'Virgin Islands.*': 'VI',\n",
    "    r'Virginia.*': 'VA',\n",
    "    r'Washington.*': 'WA',\n",
    "    r'West V.*': 'WV', # Written in different ways\n",
    "    r'Wisconsin.*': 'WI',\n",
    "    r'Wyoming.*': 'WY'\n",
    "}\n",
    "\n",
    "# Convert states to two letter abbreviations\n",
    "Data116['State'] = Data116['State'].replace(regex = us_state_abbrev)\n",
    "\n",
    "# Remove @\n",
    "Data116 = Data116.replace(regex = {r'^@': ''})\n",
    "\n",
    "# Remove vacant positions\n",
    "Data116 = Data116[Data116.Name != \"Vacant\"]\n",
    "\n",
    "# Look at the data\n",
    "Data116"
   ]
  },
  {
   "source": [
    "It is also seen that there are an inconsistency in the ways the names are written. This is changed so all names are written with the first name first:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data116['Name'] = [name[1][1:]+ \" \" +name[0] if len(name) == 2 else name[0] for name in [name.replace(u'\\xa0', u'').split(',') for name in Data116.Name]]"
   ]
  },
  {
   "source": [
    "#### 115<sup>th</sup> congress\n",
    "\n",
    "Now we move onto the 115th congress. This is data stored in a pdf.table, so for this the `camelot` library is used. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "file115 = '../Data/Raw/115_congress_twitter.pdf'\n",
    "\n",
    "# Read table across all pages\n",
    "tables = camelot.read_pdf(file115, pages = 'all')\n",
    "\n",
    "# Convert data to pandas data frame\n",
    "Data115 = pd.DataFrame(np.concatenate([d.df.drop(0).values for d in tables]), columns=tables[0].df.iloc[0]).drop(columns = \"District\")\n",
    "\n",
    "# Align chamber name with the 116 data\n",
    "rename_chamber = {'Rep.': 'Representative', 'Sen.': 'Senator'}\n",
    "Data115 = Data115.replace(rename_chamber)\n",
    "\n",
    "# Align name with the 116 data and store it in one column\n",
    "Data115[\"Name\"] = Data115[\"First Name\"] + \" \" + Data115[\"Last Name\"]\n",
    "Data115 = Data115.drop(columns = [\"First Name\", \"Last Name\"])\n",
    "\n",
    "# Align columns name with the 116 data\n",
    "Data115 = Data115.rename(columns = {'Title': 'Type', \"Twitter Handle\": \"Twitter\"})"
   ]
  },
  {
   "source": [
    "#### Merge data\n",
    "\n",
    "Now the two datasets are merged. Here we need to take duplicate acounts into account which accounts for reelections."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data set\n",
    "Data_Full = Data115.append(Data116, ignore_index = True)\n",
    "\n",
    "# Get shape\n",
    "Data_Full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra duplicate from AS\n",
    "Data_Full = Data_Full[Data_Full.Twitter != 'RepTomPrice']\n",
    "\n",
    "# Drop closed users\n",
    "Data_Full = Data_Full[~Data_Full.Name.isin(['Aumua Radewages', 'Madeleine Bordallo', 'Elizabeth Esty'])]\n",
    "\n",
    "# Fix Eric\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Erik Paulsen\"].index,\"Twitter\"] = \"ErikPaulsen\"\n",
    "\n",
    "# Fix Bobby\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Bobby Scott\"].index,\"Twitter\"] = \"BobbyScott\"\n",
    "\n",
    "# Fix Dave\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Dave Reichert'].index,\"Twitter\"] = \"TeamReichert\"\n",
    "\n",
    "# Fix Lindsey\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Lindsey Graham'].index,\"Twitter\"] = \"LindseyGrahamSC\"\n",
    "\n",
    "# Darin's name\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"arin LaHood\"].index,\"Name\"] = \"Darin LaHood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Twitter\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Name\"], keep = 'last')"
   ]
  },
  {
   "source": [
    "#### Adding the President"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.append({'State': None, 'Party': 'R', 'Type': 'POTUS', 'Twitter': 'realDonaldTrump', 'Name': 'Donald J. Trump', 'twitter_display_name': 'Donald J. Trump'}, ignore_index=True)"
   ]
  },
  {
   "source": [
    "#### Merging data including media and correct period (1: 27.01.2017-02.01.2019, 2: 27.01.2019-07.05.2020)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_pickle('../Data/Interim/congress.pkl')\n",
    "trump = pd.read_pickle('../Data/Interim/trump.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinating the congress with Trump\n",
    "congress_tweets = pd.concat([congress, trump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "congress_tweets.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting handles\n",
    "medias = pd.read_table('../Data/Raw/LargestMedia.csv', sep=';')\n",
    "twitter_handles = pd.read_table('../Data/Processed/Twitter_Handles_updated.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding relevant columns to media dataframe\n",
    "medias['State'] = None\n",
    "medias['Party'] = None\n",
    "medias['Type'] = 'Media'\n",
    "medias.rename(columns={'Twitter name': 'Twitter', 'Media': 'Name'}, inplace=True)\n",
    "\n",
    "Data_Full = pd.concat([twitter_handles, medias])"
   ]
  },
  {
   "source": [
    "How have we cleaned and preprocessed the tweets..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Discussion of dataset stats\n",
    "\n",
    "#### Network size\n",
    "\n",
    "#### Degree distribution\n",
    "\n",
    "#### Average distance\n",
    "\n",
    "#### Clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Tools, theory and analysis\n",
    "\n",
    "In this section, we will go through how we've worked with the text and which network science tools and data analysis strategies we've used for solving the problem about how the political polarization is expressed on Twitter. \n",
    "\n",
    "<img src=\"../figures/tools.png\" width=360 height=250/>\n",
    "\n",
    "\n",
    "### Idea\n",
    "The overall idea is to use the tools and methods learned in this course to find interesting results about the political polarization. We will explore the coherence of the congress by considering three graphs that are generated with different view on the Twitter data. One graph investigates who follows whom in the congress. Do senators follow senators? Do republicans follow republicans? And so on. Another graph examines whether the political polarization is expressed in the retweets. In this graph the media are also taken into account in order to explore possible patterns of retweets from other sources. By comparing the 'Follow'-graph with the 'Retweet'-graph, we probably get insight into whether people are only lurking on their opponents. Furthermore, a graph visualizing the tags in each tweet is constructed. Do republicans tag democrats? And is the relation to the tag positive or negative? This graph brings us to the text processing in the form of sentiment analysis. We want to examine whether there exist patterns in the language based on what part of the congress and party people belong to. By using TF-TR, word clouds can be created and hopefully they will show some interesting points with regards to the political polarization.\n",
    "\n",
    "The points of interest for each analysis will be described in more detail in the following subsections. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Analysis step 1 - The 'Who Follows Whom'-graph\n",
    "\n",
    "follow graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Analysis step 2 - The 'Who Retweets Whom'-graph\n",
    "\n",
    "retweet graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Analysis step 3 - Natural Language Processing\n",
    "tag graph\n",
    "\n",
    "sentiment analysis\n",
    "\n",
    "text analysis\n",
    "\n",
    "tf-tr\n",
    "republicaner vs demokrater -> word clouds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Discussion\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Contributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## References\n",
    "\n",
    "#### Links\n",
    "[https://developer.twitter.com/en/docs/twitter-api]\n",
    "\n",
    "\n",
    "[http://www.trumptwitterarchive.com]\n",
    "\n",
    "[https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/UIVHQR]\n",
    "\n",
    "[https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/MBOJNS]\n",
    "\n",
    "### Papers/books\n",
    "Albert-Laszlo Barabasi. (2015). Network Science. Cambridge: Cambridge University Press. \n",
    "http://networksciencebook.com"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}