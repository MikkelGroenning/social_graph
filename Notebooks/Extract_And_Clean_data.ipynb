{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data used to perform the analysis\n",
    "\n",
    "The precidency of Donald J. Trump began at noon EST (17:00 UTC) on January 20, 2017 when he was inaugurated as the 45th president of the United States, and will com to an end the on January 20, 2021 as he ultimately lost the 2020 presidential election to Joe Biden. It is not far fetched to say it has been bizare precidency compared to the most recent precidencies. \n",
    "\n",
    "It feels like America has been splitted in two the suporters of Trump and those agianst him - Repulicans agianst Democrats. In this project we wanted to explore if our hypothesis of polarization can be seen or rejected by analyzing the Congress of United States behavoir on the social media Twitter including the infamous Twitter account manged by Donald J. Trump. The idea was to analyze the congress tweets from the time of the 45th precidency to explore potential polarization.\n",
    "\n",
    "With access to the Twitter API it is only possible to exctract the most reason 3200 tweets from a given account (3200 tweet do not go far back for many american polticians). However, Twitter's Terms of Service do allow for datasets of tweets ID's to be distributed to third parties (not the full JSON). Luckily we found two sources that keep tweet id open very related to our project and one sources that stored the full length tweets of Donald Trump namely:\n",
    "\n",
    "* **115th U.S. Congress Tweet Ids:**\n",
    "    A open dataset with 2,041,399 tweets from the Twitter accounts of members of the 115th U.S. Congress collected in the period of January 27, 2017 and January 2, 2019. The dataset consists two files of interest namely\n",
    "    * `senators-1.txt` that contains tweet ids for Seneators\n",
    "    * `representatives-1.txt` that contains tweet ids for Representatives\n",
    "    *Littman, Justin, 2017, \"115th U.S. Congress Tweet Ids\", https://doi.org/10.7910/DVN/UIVHQR, Harvard Dataverse, V5.*\n",
    "\n",
    "* **116th U.S. Congress Tweet Ids**\n",
    "    A open dataset with 2,817,747 tweets from the Twitter accounts of members of the 116th U.S. Congress collected in the period of January 27, 2019 and May 7, 2020.  The dataset consists two files of interest namely\n",
    "    * `Senators: congress116-senate-ids.txt` that contains tweet ids for Seneators\n",
    "    * `Representatives: congress116-house-ids.txt` that contains tweet ids for Representatives  * Wrubel, Laura; Kerchner, Daniel, 2020, \"116th U.S. Congress Tweet Ids\", https://doi.org/10.7910/DVN/MBOJNS, Harvard Dataverse*\n",
    "\n",
    "* **Trump Twitter Archive**\n",
    "    A site dedicated to scrape every single tweet from Donald J. Trump. Here we downloaded all tweets in the periods of January 27, 2017 and January 2, 2019 and January 27, 2019 and May 7, 2020. https://www.thetrumparchive.com/\n",
    "\n",
    "Examing the Harvard Dataverse we discovered that polticians in congress can have number of profiles for instance a private profile, a profile associated with work in congress and campaign profile. Unfortunally the data also contains a large number of random profiles. Moreover there is tweet dateing as far back as 2008. Furthermore it was not listed what party the account where associated with. However, we found a list of congress memebers with their party association, whether they act as Senator or Represenative and, most important for the project, their twitter profile (if they have an account the vast majority has). That meant rather than dealing with multiple accounts for the same congress member or including random account we would only consider one account per congress member. Two different sources for the 115 and 116 congress have been utilized for this namely\n",
    "\n",
    "* 116. Congress twitter info: (website) https://triagecancer.org/congressional-social-media \n",
    "* 115. Congress twitter info : (PDF) https://www.sciencecoalition.org/wp-content/uploads/2018/09/115th-Congress-Twitter-Handles.pdf  \n",
    "\n",
    "The politicans listed in these to documents as well as Donald Trump are the twitter profiles that ones that will considered. The information needs to scraped as the format is HTML and PDF respectively.\n",
    "\n",
    "# Handeling the Data\n",
    "This notebook will explain how the above described data was exstracted and preprocessed. The easist way to re-create the data is to clone the github repository: https://github.com/MikkelGroenning/social_graph and setup the corrosponding conda environment and run this Notebook.  The notebook consist of four parts and one smaller part devoted to extrating Trump tweets id (part 0). So in total:\n",
    "* **Part 0: Exstract Trump Tweet IDs**\n",
    "    Here the tweet id are exstacted from the tweets made publicly by https://www.thetrumparchive.com/\n",
    "\n",
    "* **Part 1: Hydrate Tweets**\n",
    "    In this part all the tweet ids from Harvard data archive as well as Trumps tweet id, are hydrated. I.e. the ids are turned back into tweets with metadata. \n",
    "\n",
    "* **Part 2: Getting Congress Twitter Account**\n",
    "    Here a pandas data frame is constructed from information scraped from the PDF describing the 115 Congress memebers twitter accounts, and the HTML site describing the 116 Congress Twitter info.\n",
    "\n",
    "* **Part 3: Clean-up of Harward Data**\n",
    "    The Harvard data archive needs to be cleaned prior to analsis as it contains\n",
    "    * Data prior to January 27, 2017\n",
    "    * Duplicates\n",
    "    * Many random profiles \n",
    "    * Remove random/duplicate twitter accounts\n",
    "    \n",
    "* **Part 4: Preprocess the twitter data**\n",
    "    Many tweets contains links, emojies etc that makes it difficult to perform natural language processing on. In this part the tweets are preprocessed such that they can be used for our analysis.\n",
    "    \n",
    "    \n",
    "Below can all the library dependicies be read. Note the import of functions from our own module `src`. The source code for these functions can be read on our github repository https://github.com/MikkelGroenning/02805_social_graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import camelot\n",
    "import tweepy\n",
    "import tqdm\n",
    "from src.data.trump_tweet_ids import get_trump_tweet_ids\n",
    "from src.data.hydrate import hydrate_tweets\n",
    "from src.tools.twitter_api_credentials import api_key, api_secret_key, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file twitter_api_credentials.py can't be found in out Github repository as it contains classified information about our creditiels to the Twitter API. To recreate the dataset one needs to access the Twitter API through developer account is needed. Such an account can be requested at https://developer.twitter.com/en/apply-for-access typically one is granted access instant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "except tweepy.TweepError:\n",
    "    print('Error! Failed to get request token.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Exstract Trump Tweet IDs\n",
    "As the site Trump Twitter Achive (https://www.thetrumparchive.com/) store Donald Trump's tweets in a different format than how it typically exstracted from Twitter-API we exstracted the tweet id from this sources and stored them in the file `trump_id.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trump_tweets1 = pd.read_csv('../Data/raw/tweets/trump_tweets_1st.csv')  \n",
    "df_trump_tweets2 = pd.read_csv('../Data/raw/tweets/trump_tweets_2nd.csv')\n",
    "df_trump = pd.concat([df_trump_tweets1, df_trump_tweets2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11326 tweet ids saved\n"
     ]
    }
   ],
   "source": [
    "filepath = \"../Data/raw/tweets/trump_id.txt\"\n",
    "get_trump_tweet_ids(df_trump, filepath)"
   ]
  },
  {
   "source": [
    "### Hydrate Tweets\n",
    "The process of turning tweet ID's into actual tweets with metadata is called *hydration* and requires Twitter delopper account. In the below cell we load all twitter ids obtained from Harward Data Archive and Trump Twitter Archive."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hydrate Tweets\n",
    "The process of turning tweet ID's into actual tweets with metadata is called *hydration* and requires Twitter delopper account. In the below cell we load all twitter ids obtained from Harward Data Archive and Trump Twitter Archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4870472\n"
     ]
    }
   ],
   "source": [
    "representatives115 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/representatives115.txt\", dtype=int\n",
    ")\n",
    "representatives116 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/representatives116.txt\", dtype=int\n",
    ")\n",
    "senators115 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/senators115.txt\", dtype=int\n",
    ")\n",
    "senators116 = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/senators116.txt\", dtype=int\n",
    ")\n",
    "trump = np.loadtxt(\n",
    "    \"../Data/Raw/Tweets/trump_id.txt\", dtype=int\n",
    ")\n",
    "congress = np.concatenate([representatives115, representatives116, senators115, senators116, trump])\n",
    "print(len(congress))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concatted into array of tweet id consist of 4.8 millions ID. All these tweet are now hydrated with the function `hydrate_tweets` located in src/data folder in our reposortiry. Note running the cell below take $24 \\pm 6$ hours as the twitter API set limits to how much can be exstracted. More info about rate limits can be found at https://developer.twitter.com/en/docs/twitter-api/v1/rate-limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../Data/interim/congress.pkl\"\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "hydrate_tweets(\n",
    "    tweet_ids=congress,\n",
    "    filepath=filepath,\n",
    "    api = api\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Getting Congress Twitter Account\n",
    "In this part a pandas data frame will generated with each members congress member's name State, Type (Reprensative, sSnator, POTUS), Name, Party. This part cosist of three subparts:\n",
    "* **Part 2.1: 116<sup>th</sup>** Here the desired data frame for 116 congress will be scraped\n",
    "* **Part 2.2: 115<sup>th</sup>** Here the desired data frame for 115 congress will be scraped\n",
    "* **Part 2.3: Merge data** Here the different congress data frame will be merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: 116<sup>th</sup> congress\n",
    "\n",
    "First the twitter handles for the 116<sup>th</sup> congress will be extracted using [this](https://triagecancer.org/congressional-social-media) source. The choice of source comes from the fact that the Twitter handle as well as the party is desired.\n",
    "\n",
    "`BeautifulSoup` is used to extract the HTML table from the webpage (that has been downloaded to allow for offline work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data\n",
    "with open('../Data/Raw/116_congress_twitter.html') as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "# Find table\n",
    "table = soup.find('table', attrs={'id':\"footable_16836\"})\n",
    "\n",
    "# Extract data row wise from table\n",
    "l = []\n",
    "for tr in table.findAll('tr'):\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "\n",
    "# Make the data into a Pandas data frame and drop irrelevant columns\n",
    "Data116 = pd.DataFrame(l[1:], columns = [header.getText() for header in table.findAll('th')]).drop(columns = ['Name Links', 'Twitter Links', 'Instagram', 'Facebook Page', 'Facebook'])\n",
    "\n",
    "# Ensure that the type of politician is alligned\n",
    "rename_chamber = {'U.S. Representative': 'Representative', 'U.S. Senator': 'Senator'}\n",
    "Data116 = Data116.replace(rename_chamber).rename(columns = {'Chamber of Congress': 'Type'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set the state is given as well as congressional district. This is fixed using regex strings as shown below. Moreover the \"@\" are removed from the Twitter handles as the Twitter API does not need it. The vancant positions in Congress are also disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>R</td>\n",
       "      <td>SenShelby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Doug Jones</td>\n",
       "      <td>D</td>\n",
       "      <td>DougJones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Byrne, Bradley</td>\n",
       "      <td>R</td>\n",
       "      <td>RepByrne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Roby, Martha</td>\n",
       "      <td>R</td>\n",
       "      <td>RepMarthaRoby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Rogers, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>RepMikeRogersAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>WI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Tiffany, Thomas</td>\n",
       "      <td>R</td>\n",
       "      <td>TomTiffanyWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>WI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Gallagher, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>MikeforWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>WY</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Enzi, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>SenatorEnzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>WY</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Barrasso, John</td>\n",
       "      <td>R</td>\n",
       "      <td>SenJohnBarrasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>WY</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Cheney, Liz</td>\n",
       "      <td>R</td>\n",
       "      <td>Liz_Cheney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State            Type             Name Party          Twitter\n",
       "0      AL         Senator   Richard Shelby     R        SenShelby\n",
       "1      AL         Senator       Doug Jones     D        DougJones\n",
       "2      AL  Representative   Byrne, Bradley     R         RepByrne\n",
       "3      AL  Representative     Roby, Martha     R    RepMarthaRoby\n",
       "4      AL  Representative     Rogers, Mike     R  RepMikeRogersAL\n",
       "..    ...             ...              ...   ...              ...\n",
       "536    WI  Representative  Tiffany, Thomas     R     TomTiffanyWI\n",
       "537    WI  Representative  Gallagher, Mike     R        MikeforWI\n",
       "538    WY         Senator       Enzi, Mike     R      SenatorEnzi\n",
       "539    WY         Senator   Barrasso, John     R  SenJohnBarrasso\n",
       "540    WY  Representative      Cheney, Liz     R       Liz_Cheney\n",
       "\n",
       "[537 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All states abbreviations\n",
    "us_state_abbrev = {\n",
    "    r'Alabama.*': 'AL',\n",
    "    r'Alaska.*': 'AK',\n",
    "    r'American Samoa.*': 'AS',\n",
    "    r'Arizona.*': 'AZ',\n",
    "    r'Arkansas.*': 'AR',\n",
    "    r'California.*': 'CA',\n",
    "    r'Colorado.*': 'CO',\n",
    "    r'Connecticut.*': 'CT',\n",
    "    r'Delaware.*': 'DE',\n",
    "    r'District of Columbia.*': 'DC',\n",
    "    r'Florida.*': 'FL',\n",
    "    r'Georgia.*': 'GA',\n",
    "    r'Guam.*': 'GU',\n",
    "    r'Hawaii.*': 'HI',\n",
    "    r'Idaho.*': 'ID',\n",
    "    r'Illinois.*': 'IL',\n",
    "    r'Indiana.*': 'IN',\n",
    "    r'Iowa.*': 'IA',\n",
    "    r'Kansas.*': 'KS',\n",
    "    r'Kentucky.*': 'KY',\n",
    "    r'Louisiana.*': 'LA',\n",
    "    r'Maine.*': 'ME',\n",
    "    r'Maryland.*': 'MD',\n",
    "    r'Massachusetts.*': 'MA',\n",
    "    r'Michigan.*': 'MI',\n",
    "    r'Minnesota.*': 'MN',\n",
    "    r'Mississippi.*': 'MS',\n",
    "    r'Missouri.*': 'MO',\n",
    "    r'Montana.*': 'MT',\n",
    "    r'Nebraska.*': 'NE',\n",
    "    r'Nevada.*': 'NV',\n",
    "    r'New Hampshire.*': 'NH',\n",
    "    r'New Jersey.*': 'NJ',\n",
    "    r'New Mexico.*': 'NM',\n",
    "    r'New York.*': 'NY',\n",
    "    r'North Carolina.*': 'NC',\n",
    "    r'North Dakota.*': 'ND',\n",
    "    r'Northern Mariana Islands.*':'MP',\n",
    "    r'Ohio.*': 'OH',\n",
    "    r'Oklahoma.*': 'OK',\n",
    "    r'Oregon.*': 'OR',\n",
    "    r'Pennsylvania.*': 'PA',\n",
    "    r'Puerto Rico.*': 'PR',\n",
    "    r'Rhode Island.*': 'RI',\n",
    "    r'South Carolina.*': 'SC',\n",
    "    r'South Dakota.*': 'SD',\n",
    "    r'Tennessee.*': 'TN',\n",
    "    r'Texas.*': 'TX',\n",
    "    r'Utah.*': 'UT',\n",
    "    r'Vermont.*': 'VT',\n",
    "    r'Virgin Islands.*': 'VI',\n",
    "    r'Virginia.*': 'VA',\n",
    "    r'Washington.*': 'WA',\n",
    "    r'West V.*': 'WV', # Written in different ways\n",
    "    r'Wisconsin.*': 'WI',\n",
    "    r'Wyoming.*': 'WY'\n",
    "}\n",
    "\n",
    "# Convert states to two letter abbreviations\n",
    "Data116['State'] = Data116['State'].replace(regex = us_state_abbrev)\n",
    "\n",
    "# Remove @\n",
    "Data116 = Data116.replace(regex = {r'^@': ''})\n",
    "\n",
    "# Remove vacant positions\n",
    "Data116 = Data116[Data116.Name != \"Vacant\"]\n",
    "\n",
    "# Look at the data\n",
    "Data116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also seen that there are an inconsistency in the ways the names are written. This is changed so all names are written with the first name first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data116['Name'] = [name[1][1:]+ \" \" +name[0] if len(name) == 2 else name[0] for name in [name.replace(u'\\xa0', u'').split(',') for name in Data116.Name]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: 115<sup>th</sup> congress\n",
    "\n",
    "Now we move onto the 115th congress. This is data stored in a pdf.table, so for this the `camelot` library is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "file115 = '../Data/Raw/115_congress_twitter.pdf'\n",
    "\n",
    "# Read table across all pages\n",
    "tables = camelot.read_pdf(file115, pages = 'all')\n",
    "\n",
    "# Convert data to pandas data frame\n",
    "Data115 = pd.DataFrame(np.concatenate([d.df.drop(0).values for d in tables]), columns=tables[0].df.iloc[0]).drop(columns = \"District\")\n",
    "\n",
    "# Align chamber name with the 116 data\n",
    "rename_chamber = {'Rep.': 'Representative', 'Sen.': 'Senator'}\n",
    "Data115 = Data115.replace(rename_chamber)\n",
    "\n",
    "# Align name with the 116 data and store it in one column\n",
    "Data115[\"Name\"] = Data115[\"First Name\"] + \" \" + Data115[\"Last Name\"]\n",
    "Data115 = Data115.drop(columns = [\"First Name\", \"Last Name\"])\n",
    "\n",
    "# Align columns name with the 116 data\n",
    "Data115 = Data115.rename(columns = {'Title': 'Type', \"Twitter Handle\": \"Twitter\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3: Merge data\n",
    "\n",
    "Now the two datasets are merged. Here we need to take duplicate acounts into account which accounts for reelections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data set\n",
    "Data_Full = Data115.append(Data116, ignore_index = True)\n",
    "\n",
    "# Get shape\n",
    "Data_Full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below is Twitter display name exstracted with twitter API for full data. This is done as the full name does not always match the Twitter Display Name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1072it [16:04,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "to_remove = []\n",
    "twitter_display_name = []\n",
    "for index, handle in tqdm.tqdm(enumerate(Data_Full.Twitter)):\n",
    "    try:\n",
    "        u=api.get_user(handle)\n",
    "    except Exception:\n",
    "        to_remove.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop(index=to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra duplicate from AS\n",
    "Data_Full = Data_Full[Data_Full.Twitter != 'RepTomPrice']\n",
    "\n",
    "# Drop closed users\n",
    "Data_Full = Data_Full[~Data_Full.Name.isin(['Aumua Radewages', 'Madeleine Bordallo', 'Elizabeth Esty'])]\n",
    "\n",
    "# Fix Eric\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Erik Paulsen\"].index,\"Twitter\"] = \"ErikPaulsen\"\n",
    "\n",
    "# Fix Bobby\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Bobby Scott\"].index,\"Twitter\"] = \"BobbyScott\"\n",
    "\n",
    "# Fix Dave\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Dave Reichert'].index,\"Twitter\"] = \"TeamReichert\"\n",
    "\n",
    "# Fix Lindsey\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Lindsey Graham'].index,\"Twitter\"] = \"LindseyGrahamSC\"\n",
    "\n",
    "# Darin's name\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"arin LaHood\"].index,\"Name\"] = \"Darin LaHood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Twitter\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Name\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the President"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.append({'State': None, 'Party': 'R', 'Type': 'POTUS', 'Twitter': 'realDonaldTrump', 'Name': 'Donald J. Trump', 'twitter_display_name': 'Donald J. Trump'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_display_name = [api.get_user(handle).name for handle in Data_Full.Twitter]\n",
    "Data_Full['twitter_display_name'] = twitter_display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full.to_csv('../Data/Processed/Twitter_Handles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Clean-up of Harward Data\n",
    "In this part the Harward data is cleaned such that:\n",
    "* It only contains tweets from account from `Data_Full`. \n",
    "* There is only tweets from the two periods of January 27, 2017 to January 2, and 2019 January 27, 2019 to May 7, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_pickle('../Data/Interim/congress.pkl')\n",
    "twitter_handles = pd.read_table('../Data/Processed/Twitter_Handles_updated.csv', sep = ',')\n",
    "\n",
    "s1 = set(twitter_handles['twitter_display_name'])\n",
    "s2 = set(congress.user_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below can non-overlapping twitter profile between the dataframe containing tweets from congress and the data frame created in part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'US Rep Brendan Boyle',\n 'くたくたのけいたろ',\n 'lulur',\n '𝓑𝓱𝓾𝓿𝓪𝓷𝓮𝓼𝓱 𝔀𝓪𝓻𝓪𝓷',\n 'Fran Givens',\n 'Ma yuyu',\n '🍒',\n 'Cesar Andres💙👨\\u200d👩\\u200d👧\\u200d👧🐍🇨🇱',\n 'Sarisa06',\n 'Martha McSally for U.S. Senate',\n 'Hank Johnson',\n 'Du_Balão',\n 'Bill Flores',\n '♡𝘄𝗶𝗸𝗮⁷♡',\n 'Jesús “Chuy” García',\n 'Rike',\n 'MatthewBroome',\n 'Exequiel🇦🇷🇨🇱🇵🇾',\n 'Rep. Mike Kelly',\n 'Cryptbuzz',\n 'Thomas Parker',\n 'Idy',\n 'O patrão 🤡',\n 'ᴮᴱ ᴍᴏᴍᴏ⁷ 👑 || ʙɪʟʟʙᴏᴀʀᴅ #1 ᴀʀᴛɪꜱᴛꜱ',\n 'Dr. jawaher \\U0001f90d',\n 'Vallenato FM',\n 'Ancor',\n 'Adrian',\n 'Dan Sullivan',\n 'S H I M A A ❤️',\n 'HollyHill',\n 'Pame🤪',\n 'Cecy Badillo',\n 'alice ♥',\n 'Mark E. Green, MD',\n 'mari',\n 'dia🎏 앚',\n 'Steven Palazzo',\n 'Djeni 🦋',\n 'Dave Loebsack for Iowa',\n '💎 T',\n 'Deb',\n 'Duarte & Partner',\n 'Ron Johnson',\n 'Eric Swalwell',\n 'TeaDay 10/17',\n 'ChingasX',\n 'Nicola Vietri',\n 'ᴮᴱsisi⁷🦋',\n 'Donna E. Shalala',\n 'நிலானி',\n 'DBSstudent927',\n \"• Mina D'Iemanjá •\",\n 'Jennifer Wexton',\n 'Donna',\n 'luana',\n 'Rep. Paul Mitchell',\n 'Hurricane🌌Bady',\n 'Spies Santana 🕊',\n '🏚',\n 'Greg Steube',\n 'Afnan',\n 'Jorge Rey',\n 'Xochitl Torres Small',\n 'Tagaa🇸🇳',\n 'G',\n 'Mighty JJ',\n 'Ayanfe Obilana',\n 'Pat Roberts',\n 'Mukomana Weku Ruwa',\n 'Peter por la Autonomía',\n 'Declan Shalvey',\n '#freeeromz🧖🏿\\u200d♀️#ENDSARS #ENDSARSNOW',\n 'Matheus ✠ ✊🏾',\n 'HJ〽️',\n 'Lisa Henney',\n 'ѕтєνє',\n '✨ᶜʳᶠ',\n 'Meggilyweggily',\n 'manu #SantaDose',\n 'SWRV 金 VITO🏁🐍',\n 'Derek Kilmer',\n 'Narcissistic Abuse Rehab / #MenHealing',\n 'Carolina',\n 'Frank LoBiondo',\n 'ハトムギ',\n 'ハ゜クマン(´･_･`)',\n 'Dt.AFNAN~',\n 'Susan Brooks',\n 'りゅうじん',\n 'kiarra.👨🏿\\u200d🦰',\n 'Juliana Guedes',\n 'Daniela🌙\\U0001fa90',\n '🇹🇷🇹🇷🇹🇷🇹🇷🇹🇷🇹🇷',\n 'Paul Shoulberg',\n 'パチョ（´-`\\u3000）',\n 'たこけつ',\n 'Anthony Brindisi',\n 'Mathys',\n 'calvin',\n '‘ kee🥳',\n 'Ruben J. Kihuen',\n 'bangtan & army',\n 'necoko@ねここここここここここ',\n 'Qui voilà-je?',\n 'suquinho',\n 'Bob Casey Jr.',\n 'samantha davis',\n 'Yuichi WATANABE',\n 'Thu Phương _ 아부❤❤',\n 'Nicole Locke',\n 'ぱみゅれンゴ',\n 'Gregg in FL',\n 'B',\n 'Ολά Καλά',\n 'Jason Crow',\n '☆ multilisting.su ☆',\n 'Darren Soto',\n 'sabzq',\n 'Eco Goth',\n 'Tom Malinowski',\n 'GCSE MEMES 🎩',\n 'Deise 💟',\n '#TonyCardenas🇺🇸',\n 'Natália',\n 'Rep. Ilhan Omar',\n 'James Angus',\n '夏芽@ポケモントレーナー兼審神者',\n \"Oleg's bizarre adventure\",\n 'MaJo',\n 'Salvador Ramírez',\n '⎯𝘽𝖨𝖫𝖫𝖸.',\n 'Andy',\n 'barry laughton',\n 'سلیمان شاہ',\n 'ᴛʀɪs || 𝒇𝒐𝒍𝒌𝒍𝒐𝒓𝒆⁷',\n 'Pete Aguilar',\n 'LuisPé',\n 'yasmeen🌻',\n 'nath ❤',\n \"خـليل 💙'\",\n 'Team GT - Friends of Glenn Thompson',\n 'Edickson Pantoja',\n 'منخفض نجد',\n 'Rick Larsen',\n 'ωasskuu ㋡',\n 'lovelyluckylife',\n 'Cami Vargas🐟',\n 'spooky isa 🎃',\n 'Taylor',\n '↬linna OUT DE TRETAS',\n 'Scott Peters',\n 'Pieter',\n '風死',\n 'Greg Stanton',\n 'Tim Waddy',\n 'Adam',\n 'pupuce',\n 'αlժαղα⚘',\n '@JasonSmithMO',\n 'Ivanilda Maria',\n 'Emir Diblan',\n 'Ron Estes',\n 'oceano é pacifico eu não♐️',\n 'Fresh Me Up',\n 'Archive: Senator McCaskill Office',\n '𝕰𝖑𝕮𝖎𝖉♑',\n 'Mike Fitzpatrick',\n 'Barry Loudermilk',\n 'William McCarren',\n 'なる',\n 'Eric Sturrock',\n 'Hope Dreemurr',\n 'Colin Allred',\n 'Arno Roa',\n 'Senator Hawley Press Office',\n 'bebecita 💗',\n 'Mohammad Ameer Hamza ➐',\n 'Sean Duffy',\n 'َ',\n 'Dr. Ralph Abraham',\n 'Lloyd Smucker',\n 'piera bianchi',\n 'Javi',\n 'لـ محمد احمد المزروعي',\n 'Anja Hoffmann',\n 'Rep. Jamie Raskin',\n 'US Rep. Al Lawson Jr',\n 'Lucy McBath',\n 'ace 💉',\n 'aiko',\n 'Nomhle🌹',\n 'Vero',\n 'Valen',\n 'Harriet Mearns-Thomas',\n 'robtherich😈',\n 'Liz🐱',\n 'Marsha Blackburn',\n 'Don Young',\n 'Mr.GettaBag💰',\n 'stan',\n 'Jason Chaffetz',\n 'Suvi🌟',\n 'Dick Durbin',\n 'Rep. Donald McEachin',\n 'A L E',\n 'jord',\n 'Flyest Anakin',\n 'lil spanish girl 💍',\n 'dawn',\n 'Nso.1391',\n 'ᴮᴱJ.Yiing⁷',\n 'Sean Casten',\n 'maybe: aliya',\n '𝐴𝑛𝑎🦕',\n 'TNC',\n 'lampião niilista',\n '𝐦𝐚𝐧𝐨𝐧 | 𝐯𝐢𝐥𝐮 𝐜𝐚𝐬𝐭 𝐚𝐭 𝐝𝐢𝐚𝐡𝟔',\n 'Team McCaul',\n 'Brian Schatz',\n 'William Monastero',\n 'CostaParda',\n 'Rob Miech',\n 'Kristaps',\n 'Crossroads Church',\n 'Catalina B.',\n 'MLi✊🏿',\n 'scarlett x',\n 'Alexander Thorvaldsen',\n 'Almutairy~',\n 'Cleaver For Congress 🗳',\n 'Johnny Roy',\n 'Cindy Axne',\n 'Sai Krish',\n 'Susie Lee',\n 'Dr. Kim Schrier',\n 'Massilva Dihya',\n 'Umyo🐰우묘',\n \"Fay 's secrets&lies\",\n 'Yvette D. Clarke for Congress',\n 'Tom Carper',\n 'Pete Visclosky',\n 'Freedom_isn’t_Free_2020_Beyond',\n 'Haifa Saleh',\n 'シュン。',\n 'Wear a damn mask',\n 'Gossip8.com',\n 'siemprecarelocoymarginado',\n 'Tim Burchett',\n '션마의 소실',\n '𝕬𝖗𝖎𝖊𝖑 𝕽𝖎𝖇𝖊𝖎𝖗𝖔',\n 'Team Reichert',\n 'Noha ♊🇪🇬',\n 'Gil Cisneros',\n 'Son_of_Chief',\n 'Ronaldo Almeida',\n 'Nica Justo',\n 'tony lukasavage',\n 'Florent Villain Nguyen',\n 'Test Account1',\n 'فرفوش وهفرفشك معايا يا بضين',\n 'Thom Tillis',\n 'David Cicilline',\n '✠𝕮𝖎𝖓𝖙𝖎𝖆✠',\n 'Mark James',\n 'Всеволод Храбров',\n 'Bayram Trust',\n 'Mitt Romney',\n 'Governor Kristi Noem',\n 'Rep. John Rutherford',\n 'Luther Strange',\n 'Mike',\n '青含',\n 'STEPHENMAKESART',\n 'Rep. Pete Olson',\n 'NMWriter',\n 'prin',\n 'Jordan Wilson',\n 'Fitness Nutrition',\n 'Viktoria❣️',\n 'Mark Warner HQ',\n 'Rak paz paz paz',\n 'Jean Simon jsimon73',\n 'TJ Cox',\n 'noah༄',\n 'Rob Wittman',\n 'Bob Latta',\n 'Louise Slaughter',\n 'Dave Trott',\n 'nursya',\n 'Spencer Shroyer',\n 'キキ',\n 'Mark Acklin ✭',\n 'Congressman Jeff Van Drew',\n 'Alfonsina 💛',\n '✌🏿✌🏿',\n 'Congressman Dan Bishop',\n 'kuwait',\n 'Lynda Garibaldi',\n '🎄 ◤𝓥𝑜𝓇𝓉𝑒𝓍◥ PaDoRu 🎄',\n 'Fede Raspanti',\n 'Kelly Armstrong',\n 'Taata Nyunyu🇺🇬',\n 'La Huerta Patria 🇻🇪 VEN VAMOS JUNT🌱S',\n 'Rep. Brian Mast',\n 'Ginny',\n 'Camila Cabello',\n '𝔖𝔞𝔟𝔯𝔦𝔫𝔞❞',\n 'Guy Reschenthaler',\n 'Josh Harder',\n '🖤',\n 'Chris Stewart',\n 'RoadRunner',\n '🤸🏻\\u200d♀️',\n 'PuffPlug',\n '4ever_Crissy ♥',\n 'Exella',\n 'shai❤️',\n 'McHenry for Congress',\n 'U.S. Senator Bill Cassidy, M.D.',\n '大土豆',\n 'John Rutherford',\n 'flor de lopez',\n 'Turgut Gunturk',\n 'Doug Collins',\n 'Iramar Truffi',\n 'saissa❁༄Breath of Love ༄',\n 'yamini-gadani',\n '𝐃𝐈𝐎𝐍𝐘𝐒𝐈𝐔𝐒 🖤',\n 'Rep. Dan Bishop',\n 'Analyteek Marketing Agency',\n 'anni',\n 'Adam Smith',\n 'Eshoo for Congress',\n 'yusuf abdu',\n 'Adonis Otogari',\n 'Jim Risch for US Senate',\n 'Juan Sanchez',\n 'Cenk Keleş',\n \"₱ ♡'s ꇙꋬꋊꋬ\",\n 'ℳ𝑎𝑛𝑢👻 is a 𝒻𝒶𝒾𝓁𝓊𝓇𝑒',\n 'maria☆',\n 'Higgins for Congress',\n 'FAHAD ALBSHAIER',\n 'Angélica Serrano-Román 🇵🇷',\n 'Fortu 🦋',\n '#Ella🤸🏾\\u200d♀️ #LeonaMood🦁🇩🇴 #SuDolores❤',\n 'Laura Catalina',\n 'Louise',\n 'valent',\n 'Carlos Curbelo',\n '顾伟超',\n 'Anastasia',\n 'L.I.B. Pimp',\n \"Kevin Biersack's\",\n 'Big sad',\n 'Brett Guthrie',\n 'Haley Stevens',\n 'はやしよういち',\n 'Karen Lievisse Adriaanse',\n 'John McCain',\n 'Megan',\n 'Joe Neguse',\n 'Dean Phillips 🇺🇸',\n 'jo',\n '𝑆𝐴𝐵𝐴ᴮᴱ \\u200e✜',\n 'PG',\n 'Gina',\n 'Debbie Dingell',\n 'Eccentric Goddess',\n \"Ta'Niya Breedlove\",\n 'Armas Shercas',\n 'Alex.',\n 'Casey',\n 'The House',\n '𝘦𝘭𝘣𝘢 𝘭𝘢𝘻𝘰 𝘯𝘢𝘷𝘪𝘥𝘦ñ𝘰',\n 'Álvaro Rodríguez',\n 'crevette',\n 'Billy Long',\n 'Salva',\n 'Jim Bridenstine',\n 'Jethalal Gathha',\n 'dragovic',\n 'Maguida Schmitt🇧🇷🇧🇷',\n 'Frank Pallone, Jr.',\n '𝕰𝕷 ༗',\n '† Maruri - Sama  †',\n 'Lorenzo 🔱',\n 'Mario Pandemio',\n 'Rádio Trânsito',\n 'Mike Simpson',\n 'Abi',\n 'ᵉᵐᵐ🏹',\n '🦋zahira ~ #BLACKLIVESMATTER✨',\n 'MJ Hegar',\n 'Mum Z',\n 'Rand Paul',\n 'Brad Sherman',\n '💛 Josi_HG 🌺',\n 'らべん：ネルハク実況S&S',\n 'Tom Tiffany',\n 'wes',\n '#REDDEVILFORLIFE',\n 'John Boozman',\n '50.050 JOTA é meu vereador',\n 'Nate McMurray for Congress 2020',\n 'William Timmons',\n 'MaGbedu',\n 'Susan Wild',\n 'Senator Mike Braun',\n 'Anarchosatanist',\n 'Dusty Johnson',\n 'M. Fazal Elahi',\n 'Jeff Duncan',\n 'gorilla grip',\n 'Mike Gallagher',\n 'Todd Young',\n 'Henrique',\n 'Dennis Ross',\n 'Kendra Horn',\n '𝕭𝖆𝖓𝖓𝖆𝖍🏁',\n 'Rep. Arrington',\n 'seyyar diplomat',\n 'Pat Toomey',\n 'DanoRivi',\n 'Lester B. Pearson HS',\n 'Pluton Ver B Nero',\n 'Rep. Stephanie Murphy',\n 'andrea',\n 'اسمر',\n 'WEJDAN',\n 'josé urach 💙vote45💙',\n 'The Golden God',\n 'itzzz🔥',\n 'Sen. Cory Booker',\n 'Michael X',\n 'Solari Josyane',\n 'Scottsbluff Schools',\n 'David Trone',\n 'Yossarian',\n 'ᴵᴺᶠᴬᴹᴼᵁˢᴷᴵᴰ 🇵🇪🇺🇸',\n 'John Sarbanes',\n 'Staybridge Liverpool',\n 'ヨンス語録bot',\n 'Nico',\n 'KimyA the Challenger',\n 'Tomas: Today',\n 'cisne lojana',\n 'Sara',\n 'Senar',\n 'Kayla🧜🏿\\u200d♀️',\n 'Joe Cunningham',\n 'Luiza Linhares',\n 'Mike (Wear a Mask) Thompson',\n 'Brian Fitzpatrick',\n 'Ted Lieu',\n 'isabella ☀️',\n 'Soy Pedro Pedro',\n 'Ted Writes TWS',\n 'Glenn Grothman',\n '𝕄𝕖𝕕𝕚𝕤𝕤𝕠𝕟',\n 'Mark O. Stack',\n 'Debbie Mucarsel-Powell',\n 'Franky Lavender',\n 'Shelley ❌eyer',\n 'أحمد',\n 'わらしべ長者＠ペンタ',\n 'Rep Andy Biggs',\n 'Lizzie Pannill Fletcher',\n 'Rep. Val Demings',\n 't. 🧚🏽\\u200d♀️',\n 'Soy La Cacho',\n 'THE CHOSEN ONE',\n 'Fleur',\n 'Rep. Ruben J. Kihuen',\n 'yngri',\n 'kam the 🌙 witch',\n '(((Jerry Nadler)))',\n 'Wayne Waldo',\n 'Lauren Underwood',\n 'Wyden for Oregon',\n '😴',\n 'closed',\n 'Jose Antonio',\n 'Imran',\n 'Rep. Mike Gallagher',\n 'joona',\n 'พีพีพีพิ๊ก🚨',\n 'TXIPAYA',\n 'Fnm9',\n 'Walberg for Congress',\n 'B.B.',\n 'Just Dave',\n 'Ratio Strain',\n 'Jim Clyburn SC-06',\n 'tNr',\n '🧘🏽\\u200d♀️ Lula',\n 'Stevie Chalmers',\n 'مّ',\n 'U.S. Senator Al Franken',\n 'Gerry Connolly',\n 'viniᶜʳᶠ',\n 'Ingrid Adjes',\n 'Andres Zubelzu',\n 'แหงะ',\n 'Haya🌸',\n 'jul',\n 'hugh dancy supremacy',\n 'Mark Pocan',\n 'Александрова Анжела',\n 'Steve Watkins',\n 'Kerie505⭐️⭐️⭐️',\n 'Rhonda@Tide Girl',\n 'SerenaCockayneJones',\n 'Stephen F. Lynch',\n 'Ivy',\n 'emmaa',\n 'VJ Rishell🌹📎✌💖🖖',\n 'luci',\n 'mskathleenquinn',\n 'Farah.',\n 'Team Joe Wilson',\n '✨',\n 'John Kennedy',\n 'Certified Lover Boy',\n 'liza⁷',\n 'Dan Lipinski',\n 'deusa do olimpo',\n '🇻🇪¡¡AZUCA!! y ¡¡OLÉ!!🇪🇸',\n 'Serwi 🦋',\n 'Kathy Castor',\n 'Rep. Salud Carbajal',\n 'Maria Cantwell',\n 'Denver Lee Riggleman III',\n 'التقوى الهجر',\n 'SiteSpect',\n 'Tatan Steven',\n 'Meurig Jones',\n 'Ross Spano',\n 'KYT0305',\n 'Jared Golden for Congress',\n 'Deborah Allen',\n 'REI DA AMERICA 🇷🇺',\n 'ᴮᴱ s⁷',\n 'Scott',\n 'جهنمية',\n 'Ryan Wooledge',\n 'King for Congress',\n 'kuddy',\n 'Gwen S. Moore',\n 'Joe Manchin',\n 'Hieronymus Bosch Butt Music',\n 'neta da bruma de Avalon',\n 'Faizaan \\u2066فیضان',\n 'Richard. 🥋🤴🏾',\n '☻',\n 'Pete King',\n 'JavierluisME',\n 'Sen. Jeff Van Drew',\n 'Chip Roy',\n 'Mac Thornberry',\n 'Ann Kirkpatrick',\n 'alice',\n 'Ana Gallardo',\n 'Tulsi Gabbard 🌺',\n 'Fino Filipino',\n '🧜🏽\\u200d♀️',\n \"T.F.😎 WeThePeopleLet'sRoll🇺🇸\",\n 'Greg Vorse TV',\n 'Almirante Brown con Emilio',\n '#..⁷',\n 'Susie Bradford',\n 'Hemi✨',\n 'Isa Rey',\n 'みうら',\n 'Lozzzzz',\n 'Sen. Kirsten Gillibrand',\n 'asia',\n 'nikolai nikolov',\n \"Rep. Tom O'Halleran\",\n 'JoshYourBro',\n 'Rep. Pramila Jayapal',\n 'السامبو',\n '_sxmeyra',\n 'Bradley Byrne',\n 'kurashiyu muhammad',\n '.... അംജു .....\\uf8ff',\n 'Lois Frankel',\n 'Madeleine Dean',\n 'En fin, la hipocresía',\n 'Chris Van Hollen',\n 'Emilio MC MUTUAL',\n 'Anthony Gonzalez',\n 'memneon',\n 'Erotic Pics',\n 'Taheem C.',\n \"Candy'nin Kendisi\",\n 'j',\n 'Peony..🌼',\n 'the good soldier',\n 'Agnès 🌝',\n 'Ace',\n 'جُ',\n '🔗مـسـتـشـار بـالـصـدمـات🔗',\n 'Vicky Hartzler',\n 'c ☆ f ㅡ milktea',\n 'A',\n 'Russ Fulcher',\n 'Francesco Calandrino',\n 'ヒラ',\n 'Ton GRH',\n 'Bruno Capelão',\n 'Tina Smith',\n 'hiuru 合',\n 'Justin Willis',\n '¹⁹⁰⁷',\n 'Anthony G. Brown',\n 'uğur kotan',\n 'barbara peake wise',\n 'Steny Hoyer',\n 'M@vocab',\n '🙁',\n 'Joe Crowley',\n 'Marcelo Galeano',\n '𝖎𝖗𝖔𝖓 𝖍𝖊𝖆𝖉',\n 'prodigy04',\n 'Whitehouse for Senate',\n 'pitanga',\n 'Sen. Maggie Hassan',\n 'JOB,S&NEWS',\n '☠️',\n 'Veronica Escobar',\n 'Elizabeth Esty',\n 'Rep. Katie Hill',\n 'nathanaliel',\n 'Karen Bass',\n 'Hellbaby🧟\\u200d♂️\\U0001fa78',\n '⨟Cheoleole⨟ 𝗛𝗢𝗠𝗘;𝗥𝗨𝗡 |𝐈𝐍ㅡ𝐎𝐔𝐓|',\n 'Michael F.Q. San Nicolas',\n 'amor da sua vida',\n '🌸',\n 'Ben McAdams',\n 'Southernbelledonna',\n 'And The Tweet Goes On',\n 'Tiquito',\n 'fausto jarrín z',\n 'KiMinSeoKook⁷ᴮᴱ 🇵🇰',\n 'Diiiii🧚🏾\\u200d♂️',\n 'Anacleto Panceto 🏳️\\u200d🌈',\n 'Wilfredo Briceno',\n 'TC#BJKTURK-ER',\n 'William Peña',\n 'shakanuys',\n 'Marcin Walas💯🇵🇱 †',\n 'Marcia L. Fudge',\n 'Barcelona :-)',\n 'Tom Bombie',\n 'Carolyn B. Maloney',\n 'Sen. Grassley Press',\n 'Lori Trahan',\n 'Siya Alex Junior',\n 'Councilor of Hammanskraal',\n 'Steve Chabot',\n 'Keith Murdoch',\n '#NiUnaMenos 💚',\n 'Darrell S',\n 'Belu Musante',\n 'コカコーラ',\n 'sorry guys .',\n 'Paul Mitchell',\n 'Dwight Evans',\n 'aqil iman',\n 'Mazie Hirono',\n 'JB',\n '𝓵𝓲𝓼𝓼 ♔',\n 'jυlιa ⚡ | will see 5sos',\n 'John Conyers, Jr.',\n 'موکت بر',\n 'فيصل الرحيلي',\n '\\U0001f90d🐰III',\n 'Merceditas #SoyDel41',\n 'ジェニファーようこ',\n 'Ben Sasse',\n 'Sama .',\n 'Michael Guest',\n '©®',\n 'yerr',\n 'Naveenarunkumar',\n 'Ted Deutch',\n \"mt'ᵗʳᵉᵐ²²🤴\",\n 'sunset⁷',\n '₁₂₇⁷ ↺ blm + acab *',\n 'صحيفة الإرادة',\n 'Sophie',\n 'LangevinForCongress',\n 'Mike Bost',\n 'ابو خالد',\n 'Adrián',\n 'Gary Peters',\n 'Rick Rigazio',\n 'Ken Buck',\n 'ब-\\u200cTATA',\n 'Antonio Delgado',\n 'Елена',\n 'Mike Turner',\n 'Jiwon',\n 'Lamar Alexander',\n 'Alexandria Ocasio-Cortez',\n 'Ben Marshall',\n '玖楽bot',\n 'Congressman Fred Keller',\n 'Elise Stefanik',\n 'mama bear for biden',\n 'carolinE',\n 'Ronny Rojas R..',\n 'leah ᴮᴱ⁷',\n 'Princess Luna',\n 'uosuɥoɾ snǝɐppɐɥʇ',\n 'mamãe do Otávio 💙🤰',\n 'Marco ᶜʳᶠ',\n 'Liveoak',\n 'Bertie’s Pet Kraken',\n 'Clara McKenzie',\n 'Scott White',\n 'Paul Gosar',\n 'nath',\n '😉😥🥑oanamp11',\n 'Júlia Mussauer',\n 'Jayce',\n 'vineet kapoor',\n 'بن يربه رمظان',\n 'Debbie Stabenow',\n 'İsmail Hakkı Kavurma',\n 'Marc Veasey',\n 'Kelly',\n 'Max Rose',\n 'JN',\n 'ColliesandCakes🏴\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f',\n 'Charlie Dent',\n 'Bruce Westerman',\n 'Debbie Wasserman Schultz',\n 'Kevin Brady for Congress',\n 'Jack Mehoff',\n 'kasey \\U0001fa81 nj luvr ⁷',\n 'frida',\n 'Mary Gay Scanlon',\n 'Jon Tester',\n 'Fēngshuǐ',\n 'のん🍞',\n 'a noiva',\n 'Πρωτότυπο Αρκαδιακό μπουμερίστικο 2019 το Μαρινάκι',\n 'John Larson',\n 'Andy Levin',\n 'Mohamed Ahmed \\u2066🇩🇪\\u2069',\n 'Mike Levin',\n 'El Señor Bendecido',\n '🖤 director jeon jungkook',\n 'hip_hop_jam',\n 'Rep. Devin Nunes',\n 'Luísa',\n 'Rep. Raúl Grijalva',\n '𝚊𝚗𝚊',\n '𝖉 𝖚 𝖉 𝖆 \\uf8ff',\n 'Jerry Woods',\n 'らぴねる＠荊582',\n 'James Kraft',\n 'ベンリー甲府西店',\n '𝔞𝔟𝔯𝔦𝔩💧',\n 'Marcela Colcer',\n 'Muad’Yke',\n 'Dr. Ami Bera',\n 'Rep. Lloyd Doggett',\n 'P I S A J 🌺 E L F',\n '#Constituyente-Independiente',\n 'viviana🧚🏻',\n 'ともがゆく',\n 'Matsui for Congress',\n 'Robb_714',\n 'Paul Ryan',\n 'Igor Miras 🇾🇪',\n 'linds🦋✰🍁',\n 'Denis Liriano',\n 'Münz☭asten #675',\n 'Maria',\n 'Rep. Ro Khanna',\n 'paige',\n 'Polly Pocket',\n 'ExeMPLaR',\n 'があひ⭐️',\n 'Mike Rogers Campaign',\n 'Sen. Murphy Office',\n 'Transparencia Activa',\n 'Rep. Jimmy Panetta',\n 'Lisa',\n 'T.F. Pfyl',\n 'Mthokozisi Mpanza',\n 'Maurin',\n 'Natalia 🚀',\n 'JSBot',\n 'Samuel',\n 'alli⁷ | extremely inactive',\n 'Hera’s final Nerve',\n 'Andy Sugden',\n 'Bobby Scott',\n 'Buddy',\n 'John Johnson',\n 'Jimmie. Leafs, No Racists! Proud Algonquin Family',\n 'Joe Kennedy III',\n 'Dutch for Congress',\n 'Dan Meuser',\n 'F L O R A H. Z.',\n 'Tim Ryan',\n 'Deb Fischer',\n 'Dana Lee Hagstrom',\n '🦋𝓶𝓲𝓬𝓪𝓮𝓵𝓪🦋',\n 'Yvette Clarke',\n 'nicole⁷',\n 'h.r.',\n 'Rayane Freitas',\n 'Nzo 🌑',\n 'k⁷ ♡BLM',\n 'Alex Mooney',\n 'Bishop for Congress',\n 'Zoe Lofgren',\n 'Capito for WV',\n 'Swiss TrIck',\n 'Umarell',\n 'Lewis Wyatt',\n 'Samantha',\n 'Rod Poblete',\n '[동결] 하뇬🍑',\n 'Blake Farenthold',\n 'milind shah',\n 'ᴍᴀʀ 💕',\n 'Kayman',\n 'Bob Flynn',\n 'commonsense4all',\n 'Rep Josh Gottheimer',\n 'Jim McGovern',\n '🇹🇷 isaSNDC 🇹🇷',\n 'Ted Cruz',\n 'شَ',\n 'ludovic louvel',\n 'Annie Kuster',\n 'DOIXDÊ /EX MC 2D 🔥',\n '𝘣𝘶𝘣𝘶 ✯',\n 'sams',\n 'João Vitor Oliveira',\n 'ChartMill',\n '🇺🇸🎅🏻🤶🏻☃️👑🏈🥡🤟🏻#GoPats #6xsChamps #Jasam',\n 'Alexamarie 💖',\n 'Will Hurd',\n 'Van Taylor',\n '💙Špela💙',\n 'Bill Keating',\n 'TOota🕊💙',\n 'Andy Kim',\n 'ユーバートレッフェンbot',\n 'MOVED📌',\n 'Rep. Clay Higgins',\n 'Derick04kt1772 ᴬᴰᴺ \\u200f',\n 'Geovani Hazan',\n 'Hefeydd 🏴\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f',\n 'sham masri',\n 'E',\n 'Ahmedzaghloul',\n 'Rotexx_banging🇳🇬☝',\n 'EnZo',\n 'G/ols',\n 'EMR',\n 'Dan Kildee',\n '💅 Me',\n '🎃👺☠️Conservative Policies☠️👺🎃',\n 'Chris Pappas',\n 'KODAWARISAN',\n 'YaKulT',\n 'grimcity',\n 'Mauroy🇯🇲',\n 'FatManNick🤙🏾™️',\n 'Kindle The Reaper',\n 'moved.',\n 'Mike Garcia',\n 'ط',\n 'Pat Tiberi',\n 'Amr Khalifa',\n 'Noumu4',\n 'Solus, ACB Devotee',\n 'ハラウェイ',\n 'Michael Cloud',\n 'Ayanna Pressley',\n 'Trucker World',\n 'love',\n 'Fred Upton',\n 'Alex MacLeod',\n 'LuLu boom boom Roche',\n 'Inmaculada González',\n 'Gino Hawley',\n 'Macieldasilva23🔂100% SDV',\n 'Geschäftsführer der BRD GmbH',\n 'Seth Moulton',\n 'BMK',\n 'Senator Amy Klobuchar',\n 'Archive: Tom Graves',\n 'Derrick.',\n 'Leader McConnell',\n 'SorAlex',\n '❄✨irene✨❄',\n 'John Carter',\n 'Jimmy Gomez',\n 'andré rougier',\n 'Sérgio Campos',\n 'Mike Johnson',\n 'Big Hoss',\n 'ERO SENNIN 油',\n 'Wealthé',\n '🇮🇳अंजली झा🇮🇳 राष्ट्रप्रेमी 🚩 #जय_श्रीराम 🕉️',\n 'sergio',\n '液体ライム',\n 'AmiCerv',\n 'Rep. David Kustoff',\n 'YooY',\n 'Jörg Stephan',\n 'juli🇦🇷',\n 'maixee',\n 'Dan Crenshaw',\n 'جود 🎼.',\n 'Η Θηριοδαμάστρια',\n 'Duende',\n 'Vani',\n 'Ryan Zinke',\n 'Shanrock',\n 'Dr. Raul Ruiz',\n 'Bartosz Lisowski',\n 'Ben Cardin',\n 'Eduarda Limberger',\n 'Usaمah 🌻',\n 'RJ',\n 'Don Bacon',\n 'Ariamehr',\n 'Mikie Sherrill',\n 'KennShiesty🦄',\n 'Steve Womack',\n 'KimyDee',\n 'migi〇',\n 'Houdi 👁\\u200d🗨',\n 'Marcelino Muñoz',\n 'Fofa Mahmoud',\n 'kie',\n 'موسى الفيفي',\n 'rl powell',\n 'Kiapan 🗽🏕',\n 'Carlos Magdaleno',\n 'mako',\n 'M♥️ISÉS',\n 'John Thune',\n 'Tom Udall Press',\n 'BLACK LIVES MATTER. (Darwin thought so too)',\n 'Elaine Luria',\n 'Katerina Pantelides',\n 'Tom Price',\n 'Andrea_98',\n 'Senator Thad Cochran',\n 'احمدرشوان احمد',\n 'Norma Torres',\n 'YWCA Cambridge, MA',\n 'Darealest Hoodini',\n 'ᴮᴱ 𝚒𝚜 𝚌𝚘𝚖𝚒𝚗𝚐🔮✨',\n 'b ✶',\n 'king kerr',\n \"Schrodinger's Cat 🇮🇳\",\n 'Nydia M Velázquez',\n 'David Schweikert',\n 'Kweisi Mfume',\n 'Aerandir',\n 'Congresswoman Tenney',\n 'Rep. Liz Cheney',\n '̶Y̶̶O̶̶U̶̶S̶̶U̶̶F̶ ̶C̶̶O̶̶b̶̶R̶̶A̶ 🐍',\n 'Darcy McRae 🛡🕊🛡🕊🛡🕊#Archewell Army',\n 'calamitous intent',\n '♑',\n 'Katie Golding 🏍 FEARLESS is OUT NOW',\n '.',\n 'Carlitos Colomes',\n 'Smama📎',\n 'Cathy McMorris Rodgers',\n 'Ron Kind',\n 'Barbara Lee',\n 'Maria Isabel',\n 'Kevin Cramer',\n 'أمل 🦋',\n 'Jeff Merkley',\n '𓅓',\n 'Rodneyfrt🇧🇷',\n 'Le360',\n '𝓘 𝓪𝓶 𝔀𝓸𝓷𝓰',\n 'Roger Wicker',\n 'grey ♈︎ EST',\n 'Greg Walden',\n 'F4MJaz 💅🏾',\n '📊ᴛʜᴀᴛ ғᴏʀᴇx ɢᴏᴅᴅᴇss ✨',\n ...}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "s1 ^ s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure tweets only comes from people that twitter handles exist for. \n",
    "congress = congress[congress.user_name.isin(s1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the periods from Harward:\n",
    "mask = (\n",
    "    #January 27, 2017 and January 2, 2019 \n",
    "    (congress.created_at > '2017-1-27 00:00:00') & (congress.created_at < '2019-1-2 00:00:00')\n",
    "    | \n",
    "    #January 27, 2019 and May 7, 2020 \n",
    "    (congress.created_at > '2019-1-27 00:00:00') & (congress.created_at < '2020-5-7 00:00:00')\n",
    ")\n",
    "congress = congress[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = congress.drop_duplicates(keep='first')\n",
    "congress = congress.sort_values(by='created_at')\n",
    "congress = congress.reset_index(drop=True)\n",
    "congress.to_pickle(\"../data/interim/congress_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1650398"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(congress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleanup results in $4,870,472-1,650,398 = 3,220,074$ less tweets than the orginal data. These tweet ids are saved such as they can be shared online with concent of Twitter. That will make it lot faster to hydrate the tweets of interest of one want to re-create the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1650398 tweet ids saved.\n"
    }
   ],
   "source": [
    "# Extract the tweets ids and convert them to integers\n",
    "ids = list(congress.id.astype(int).values)\n",
    "\n",
    "filepath = \"../Data/raw/tweets/Cleaned_tweet_id.txt\"\n",
    "with open(filepath, 'w') as output:\n",
    "    for row in ids:\n",
    "        output.write(str(row) + '\\n')\n",
    "\n",
    "    print(f'{len(ids)} tweet ids saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3.1 Shortcut to exstract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe with tweets of from congress after cleanup contain about 33 % rows of data prior to clean-up. This means it data can be hydrated much quick. Running the cell below take $8 \\pm 6$ hours and creates the same `congress` data frame as had it been cleaned up. \n",
    "The cleaned tweet id can be found at 'http://groenning.net/data/Cleaned_tweet_id.txt' as the file is too large to be on Github. The below cell make sure that the list is downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "uurl = 'http://groenning.net/data/Cleaned_tweet_id.txt'\n",
    "file_name = \"../Data/Raw/Tweets/Cleaned_tweet_id.txt\"\n",
    "\n",
    "response = urlopen(uurl)\n",
    "data = response.read()      # a `bytes` object\n",
    "text = data.decode('utf-8') # convert from bytes object\n",
    "\n",
    "with urlopen(uurl) as response, open(file_name, 'wb') as out_file:\n",
    "    data = response.read() # a `bytes` object\n",
    "    out_file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_tweet_id = np.loadtxt(\"../Data/Raw/Tweets/Cleaned_tweet_id.txt\", dtype=int)\n",
    "filepath = \"../Data/interim/congress_cleaned.pkl\"\n",
    "\n",
    "hydrate_tweets(\n",
    "    tweet_ids=congress_tweet_id,\n",
    "    filepath=filepath,\n",
    "    api = api\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Preprocess the twitter data\n",
    "In this part the cleaned tweet will processed such that the text is suited for natural language processing. The cells below do the following\n",
    "* Convert HTML tags to UTF8 symbol and text\n",
    "* Make all tweet lowercase\n",
    "* Remove all links from tweets\n",
    "* Replace all unicode whitespace with normal space\n",
    "* Remove all unknown charcters and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_pickle('../Data/Interim/congress_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_characters = \"@#\"\n",
    "character_set = {\n",
    "    \"characters\": \"abcdefghijklmnopqrstuvwxyz0123456789\" + special_characters,\n",
    "    \"space\": \" \",\n",
    "}\n",
    "alphabet = \"\".join(character_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_links = re.compile(\"http\\S+\")\n",
    "regex_whitespace = re.compile(\"[\\s|-]+\")\n",
    "regex_unknown = re.compile(f\"[^{alphabet}]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_html_tags = {\n",
    "    \"&amp\": \"and\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace unicode charetars\n",
    "for pattern_string, char in regex_html_tags.items():\n",
    "    congress[\"text\"] = congress[\"text\"].str.replace(pattern_string, char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress[\"text\"] = (congress[\"text\"]\n",
    "    .str.lower()\n",
    "    .str.replace(regex_links, \"\")\n",
    "    .str.replace(regex_whitespace, character_set[\"space\"])\n",
    "    .str.replace(regex_unknown, '')\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress.to_pickle('../Data/Processed/congress_cleaned_processed.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37964bitsocialgraphsprojectconda9e1414738f16463880d93a451ffa336f",
   "display_name": "Python 3.7.9 64-bit ('social_graphs_project': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2d507ec087116654eb570fc9cf9c6e4e826fec4ad12e36592899183da9bc57da"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}