{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import camelot\n",
    "import tweepy\n",
    "import tqdm\n",
    "from src.tools.twitter_api import auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 116<sup>th</sup> congress\n",
    "\n",
    "First the twitter handles for the 116<sup>th</sup> congress will be extracted using [this](https://triagecancer.org/congressional-social-media) source. The choice of source comes from the fact that the Twitter handle as well as the party is desired.\n",
    "\n",
    "`BeautifulSoup` is used to extract the HTML table from the webpage (that has been downloaded to allow for offline work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data\n",
    "with open('../Data/Raw/116_congress_twitter.html') as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "\n",
    "# Find table\n",
    "table = soup.find('table', attrs={'id':\"footable_16836\"})\n",
    "\n",
    "# Extract data row wise from table\n",
    "l = []\n",
    "for tr in table.findAll('tr'):\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    l.append(row)\n",
    "\n",
    "# Make the data into a Pandas data frame and drop irrelevant columns\n",
    "Data116 = pd.DataFrame(l[1:], columns = [header.getText() for header in table.findAll('th')]).drop(columns = ['Name Links', 'Twitter Links', 'Instagram', 'Facebook Page', 'Facebook'])\n",
    "\n",
    "# Ensure that the type of politician is alligned\n",
    "rename_chamber = {'U.S. Representative': 'Representative', 'U.S. Senator': 'Senator'}\n",
    "Data116 = Data116.replace(rename_chamber).rename(columns = {'Chamber of Congress': 'Type'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this data set the state is given as well as congressional district. This is fixed using regex strings as shown below. Moreover the \"@\" are removed from the Twitter handles as the Twitter API does not need it. The vancant positions in Congress are also disregarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Party</th>\n",
       "      <th>Twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Richard Shelby</td>\n",
       "      <td>R</td>\n",
       "      <td>SenShelby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Doug Jones</td>\n",
       "      <td>D</td>\n",
       "      <td>DougJones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Byrne, Bradley</td>\n",
       "      <td>R</td>\n",
       "      <td>RepByrne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Roby, Martha</td>\n",
       "      <td>R</td>\n",
       "      <td>RepMarthaRoby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Rogers, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>RepMikeRogersAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>WI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Tiffany, Thomas</td>\n",
       "      <td>R</td>\n",
       "      <td>TomTiffanyWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>WI</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Gallagher, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>MikeforWI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>WY</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Enzi, Mike</td>\n",
       "      <td>R</td>\n",
       "      <td>SenatorEnzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>WY</td>\n",
       "      <td>Senator</td>\n",
       "      <td>Barrasso, John</td>\n",
       "      <td>R</td>\n",
       "      <td>SenJohnBarrasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>WY</td>\n",
       "      <td>Representative</td>\n",
       "      <td>Cheney, Liz</td>\n",
       "      <td>R</td>\n",
       "      <td>Liz_Cheney</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State            Type             Name Party          Twitter\n",
       "0      AL         Senator   Richard Shelby     R        SenShelby\n",
       "1      AL         Senator       Doug Jones     D        DougJones\n",
       "2      AL  Representative   Byrne, Bradley     R         RepByrne\n",
       "3      AL  Representative     Roby, Martha     R    RepMarthaRoby\n",
       "4      AL  Representative     Rogers, Mike     R  RepMikeRogersAL\n",
       "..    ...             ...              ...   ...              ...\n",
       "536    WI  Representative  Tiffany, Thomas     R     TomTiffanyWI\n",
       "537    WI  Representative  Gallagher, Mike     R        MikeforWI\n",
       "538    WY         Senator       Enzi, Mike     R      SenatorEnzi\n",
       "539    WY         Senator   Barrasso, John     R  SenJohnBarrasso\n",
       "540    WY  Representative      Cheney, Liz     R       Liz_Cheney\n",
       "\n",
       "[537 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All states abbreviations\n",
    "us_state_abbrev = {\n",
    "    r'Alabama.*': 'AL',\n",
    "    r'Alaska.*': 'AK',\n",
    "    r'American Samoa.*': 'AS',\n",
    "    r'Arizona.*': 'AZ',\n",
    "    r'Arkansas.*': 'AR',\n",
    "    r'California.*': 'CA',\n",
    "    r'Colorado.*': 'CO',\n",
    "    r'Connecticut.*': 'CT',\n",
    "    r'Delaware.*': 'DE',\n",
    "    r'District of Columbia.*': 'DC',\n",
    "    r'Florida.*': 'FL',\n",
    "    r'Georgia.*': 'GA',\n",
    "    r'Guam.*': 'GU',\n",
    "    r'Hawaii.*': 'HI',\n",
    "    r'Idaho.*': 'ID',\n",
    "    r'Illinois.*': 'IL',\n",
    "    r'Indiana.*': 'IN',\n",
    "    r'Iowa.*': 'IA',\n",
    "    r'Kansas.*': 'KS',\n",
    "    r'Kentucky.*': 'KY',\n",
    "    r'Louisiana.*': 'LA',\n",
    "    r'Maine.*': 'ME',\n",
    "    r'Maryland.*': 'MD',\n",
    "    r'Massachusetts.*': 'MA',\n",
    "    r'Michigan.*': 'MI',\n",
    "    r'Minnesota.*': 'MN',\n",
    "    r'Mississippi.*': 'MS',\n",
    "    r'Missouri.*': 'MO',\n",
    "    r'Montana.*': 'MT',\n",
    "    r'Nebraska.*': 'NE',\n",
    "    r'Nevada.*': 'NV',\n",
    "    r'New Hampshire.*': 'NH',\n",
    "    r'New Jersey.*': 'NJ',\n",
    "    r'New Mexico.*': 'NM',\n",
    "    r'New York.*': 'NY',\n",
    "    r'North Carolina.*': 'NC',\n",
    "    r'North Dakota.*': 'ND',\n",
    "    r'Northern Mariana Islands.*':'MP',\n",
    "    r'Ohio.*': 'OH',\n",
    "    r'Oklahoma.*': 'OK',\n",
    "    r'Oregon.*': 'OR',\n",
    "    r'Pennsylvania.*': 'PA',\n",
    "    r'Puerto Rico.*': 'PR',\n",
    "    r'Rhode Island.*': 'RI',\n",
    "    r'South Carolina.*': 'SC',\n",
    "    r'South Dakota.*': 'SD',\n",
    "    r'Tennessee.*': 'TN',\n",
    "    r'Texas.*': 'TX',\n",
    "    r'Utah.*': 'UT',\n",
    "    r'Vermont.*': 'VT',\n",
    "    r'Virgin Islands.*': 'VI',\n",
    "    r'Virginia.*': 'VA',\n",
    "    r'Washington.*': 'WA',\n",
    "    r'West V.*': 'WV', # Written in different ways\n",
    "    r'Wisconsin.*': 'WI',\n",
    "    r'Wyoming.*': 'WY'\n",
    "}\n",
    "\n",
    "# Convert states to two letter abbreviations\n",
    "Data116['State'] = Data116['State'].replace(regex = us_state_abbrev)\n",
    "\n",
    "# Remove @\n",
    "Data116 = Data116.replace(regex = {r'^@': ''})\n",
    "\n",
    "# Remove vacant positions\n",
    "Data116 = Data116[Data116.Name != \"Vacant\"]\n",
    "\n",
    "# Look at the data\n",
    "Data116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also seen that there are an inconsistency in the ways the names are written. This is changed so all names are written with the first name first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data116['Name'] = [name[1][1:]+ \" \" +name[0] if len(name) == 2 else name[0] for name in [name.replace(u'\\xa0', u'').split(',') for name in Data116.Name]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 115<sup>th</sup> congress\n",
    "\n",
    "Now we move onto the 115th congress. This is data stored in a pdf.table, so for this the `camelot` library is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "file115 = '../Data/Raw/115_congress_twitter.pdf'\n",
    "\n",
    "# Read table across all pages\n",
    "tables = camelot.read_pdf(file115, pages = 'all')\n",
    "\n",
    "# Convert data to pandas data frame\n",
    "Data115 = pd.DataFrame(np.concatenate([d.df.drop(0).values for d in tables]), columns=tables[0].df.iloc[0]).drop(columns = \"District\")\n",
    "\n",
    "# Align chamber name with the 116 data\n",
    "rename_chamber = {'Rep.': 'Representative', 'Sen.': 'Senator'}\n",
    "Data115 = Data115.replace(rename_chamber)\n",
    "\n",
    "# Align name with the 116 data and store it in one column\n",
    "Data115[\"Name\"] = Data115[\"First Name\"] + \" \" + Data115[\"Last Name\"]\n",
    "Data115 = Data115.drop(columns = [\"First Name\", \"Last Name\"])\n",
    "\n",
    "# Align columns name with the 116 data\n",
    "Data115 = Data115.rename(columns = {'Title': 'Type', \"Twitter Handle\": \"Twitter\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge data\n",
    "\n",
    "Now the two datasets are merged. Here we need to take duplicate acounts into account which accounts for reelections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data set\n",
    "Data_Full = Data115.append(Data116, ignore_index = True)\n",
    "\n",
    "# Get shape\n",
    "Data_Full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1072it [16:04,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "to_remove = []\n",
    "twitter_display_name = []\n",
    "for index, handle in tqdm.tqdm(enumerate(Data_Full.Twitter)):\n",
    "    try:\n",
    "        u=api.get_user(handle)\n",
    "    except Exception:\n",
    "        to_remove.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop(index=to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra duplicate from AS\n",
    "Data_Full = Data_Full[Data_Full.Twitter != 'RepTomPrice']\n",
    "\n",
    "# Drop closed users\n",
    "Data_Full = Data_Full[~Data_Full.Name.isin(['Aumua Radewages', 'Madeleine Bordallo', 'Elizabeth Esty'])]\n",
    "\n",
    "# Fix Eric\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Erik Paulsen\"].index,\"Twitter\"] = \"ErikPaulsen\"\n",
    "\n",
    "# Fix Bobby\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"Bobby Scott\"].index,\"Twitter\"] = \"BobbyScott\"\n",
    "\n",
    "# Fix Dave\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Dave Reichert'].index,\"Twitter\"] = \"TeamReichert\"\n",
    "\n",
    "# Fix Lindsey\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == 'Lindsey Graham'].index,\"Twitter\"] = \"LindseyGrahamSC\"\n",
    "\n",
    "# Darin's name\n",
    "Data_Full.loc[Data_Full[Data_Full.Name == \"arin LaHood\"].index,\"Name\"] = \"Darin LaHood\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Twitter\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.drop_duplicates(subset = [\"Name\"], keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the President"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full = Data_Full.append({'State': None, 'Party': 'R', 'Type': 'POTUS', 'Twitter': 'realDonaldTrump', 'Name': 'Donald J. Trump', 'twitter_display_name': 'Donald J. Trump'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_display_name = [api.get_user(handle).name for handle in Data_Full.Twitter]\n",
    "Data_Full['twitter_display_name'] = twitter_display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Full.to_csv('../Data/Processed/Twitter_Handles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
