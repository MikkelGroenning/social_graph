{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('social_graphs_project': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2d507ec087116654eb570fc9cf9c6e4e826fec4ad12e36592899183da9bc57da"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx \n",
    "import pickle\n",
    "import re\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from svgpathtools import svg2paths\n",
    "from svgpath2mpl import parse_path\n",
    "import matplotlib as mpl\n",
    "from operator import itemgetter\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from fa2 import ForceAtlas2\n",
    "from community import community_louvain\n",
    "import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Handle_data = pd.read_csv('../Data/Processed/Twitter_Handles_updated.csv', index_col=0)\n",
    "\n",
    "with open('../Data/Processed/congress_cleaned_processed.pkl', 'rb') as handle:\n",
    "    Tweets = pickle.load(handle)\n",
    "\n",
    "with open('../Data/Processed/Usr_ID_dict.pickle', 'rb') as handle:\n",
    "    Usr_ID_dict = pickle.load(handle)\n",
    "\n",
    "ID_Usr_dict = {v: k for k, v in Usr_ID_dict.items()}"
   ]
  },
  {
   "source": [
    "Extract new data frame based on handle and tweet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Handle_Tweet_df = pd.DataFrame({\n",
    "    'Handle': Tweets['user_id'].map(ID_Usr_dict),\n",
    "    'Tweet': Tweets['text']\n",
    "})"
   ]
  },
  {
   "source": [
    "Add list of all tags as new columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Handle_Tweet_df['tags'] = [re.findall('(?<=@)\\S+',tw) for tw in Handle_Tweet_df['Tweet']]"
   ]
  },
  {
   "source": [
    "Drop columns where handle is na - this could be bacuse congress memebers have multiple accounts and the mapping misses it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Handle_Tweet_df = Handle_Tweet_df.dropna(axis = 0, subset=['Handle'])"
   ]
  },
  {
   "source": [
    "Lower all handles to allow for comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Handle_Tweet_df['Handle'] = [handle.lower() for handle in Handle_Tweet_df['Handle']]"
   ]
  },
  {
   "source": [
    "Filter out all tags that are not congress memebers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_members_lower = [usr.lower() for usr in Handle_data.index]\n",
    "Handle_Tweet_df['tags'] = [[tag for tag in tags if tag in congress_members_lower] for tags in Handle_Tweet_df['tags']]"
   ]
  },
  {
   "source": [
    "Remove all tweets that has no tags as they are not relevant in this cae"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Handle_Tweet_df = Handle_Tweet_df[[len(tags)>0 for tags in Handle_Tweet_df['tags']]]"
   ]
  },
  {
   "source": [
    "Create a new data frame that contains tweets with politicians as indecies and tagged politicians as columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df = pd.DataFrame(\n",
    "    data = '',\n",
    "    index = set(Handle_Tweet_df['Handle']),\n",
    "    columns = set([tags for tag in Handle_Tweet_df['tags'] for tags in tag])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "212274it [04:14, 832.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm.tqdm(Handle_Tweet_df.iterrows()):\n",
    "    Text_df.loc[row[1]['Handle'], row[1]['tags']] += row[1]['Tweet']+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_table = pd.read_table('../Data/Processed/Sentiment.txt', delimiter=\"\\t\")\n",
    "sentiment_dict = dict(zip(sentiment_table['word'],sentiment_table['happiness_average']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentcalc(tokens):\n",
    "    \n",
    "    # Get all words with a sentiment score from the token list\n",
    "    sents = [sentiment_dict[word] for word in tokens if word in sentiment_dict.keys()]\n",
    "    \n",
    "    # Return nan if no words have a score\n",
    "    if len(sents) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Else return the mean of scores\n",
    "    else:\n",
    "        return np.mean(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "def tokenize_tweet_calc(tweets):\n",
    "    tokens = tokenizer.tokenize(tweets)\n",
    "    return sentimentcalc(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text_df_sent = Text_df.applymap(tokenize_tweet_calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                senrobportman  repterrisewell  jeffflake  replowenthal  \\\n",
       "senrobportman        5.572385        0.000000   5.027778      0.000000   \n",
       "repterrisewell       0.000000        5.497415   0.000000      0.000000   \n",
       "jeffflake            5.413846        0.000000   5.462290      0.000000   \n",
       "replowenthal         0.000000        0.000000   0.000000      5.477669   \n",
       "staceyplaskett       0.000000        5.614857   0.000000      0.000000   \n",
       "...                       ...             ...        ...           ...   \n",
       "repkendrahorn        0.000000        0.000000   0.000000      0.000000   \n",
       "repcasten            0.000000        0.000000   0.000000      0.000000   \n",
       "warrendavidson       5.398366        0.000000   0.000000      0.000000   \n",
       "senshelby            0.000000        0.000000   0.000000      0.000000   \n",
       "repkaygranger        0.000000        0.000000   0.000000      0.000000   \n",
       "\n",
       "                staceyplaskett  repjoemorelle  sanfordbishop  repannaeshoo  \\\n",
       "senrobportman         0.000000            0.0            0.0      0.000000   \n",
       "repterrisewell        5.263119            0.0            0.0      0.000000   \n",
       "jeffflake             0.000000            0.0            0.0      0.000000   \n",
       "replowenthal          0.000000            0.0            0.0      5.796296   \n",
       "staceyplaskett        5.455182            0.0            0.0      0.000000   \n",
       "...                        ...            ...            ...           ...   \n",
       "repkendrahorn         0.000000            0.0            0.0      0.000000   \n",
       "repcasten             0.000000            0.0            0.0      0.000000   \n",
       "warrendavidson        5.876667            0.0            0.0      0.000000   \n",
       "senshelby             0.000000            0.0            0.0      0.000000   \n",
       "repkaygranger         0.000000            0.0            0.0      0.000000   \n",
       "\n",
       "                repriggleman  congressmangt  ...  repdean  usrepkeating  \\\n",
       "senrobportman            0.0            0.0  ...      0.0      0.000000   \n",
       "repterrisewell           0.0            0.0  ...      0.0      0.000000   \n",
       "jeffflake                0.0            0.0  ...      0.0      0.000000   \n",
       "replowenthal             0.0            0.0  ...      0.0      5.818966   \n",
       "staceyplaskett           0.0            0.0  ...      0.0      0.000000   \n",
       "...                      ...            ...  ...      ...           ...   \n",
       "repkendrahorn            0.0            0.0  ...      0.0      0.000000   \n",
       "repcasten                0.0            0.0  ...      0.0      0.000000   \n",
       "warrendavidson           0.0            0.0  ...      0.0      0.000000   \n",
       "senshelby                0.0            0.0  ...      0.0      0.000000   \n",
       "repkaygranger            0.0            0.0  ...      0.0      0.000000   \n",
       "\n",
       "                replipinski  repstevechabot  sentomcotton  repcasten  \\\n",
       "senrobportman      0.000000        5.594028      5.655294   0.000000   \n",
       "repterrisewell     0.000000        0.000000      0.000000   0.000000   \n",
       "jeffflake          0.000000        0.000000      0.000000   0.000000   \n",
       "replowenthal       0.000000        5.525806      0.000000   0.000000   \n",
       "staceyplaskett     0.000000        0.000000      0.000000   0.000000   \n",
       "...                     ...             ...           ...        ...   \n",
       "repkendrahorn      0.000000        0.000000      0.000000   0.000000   \n",
       "repcasten          5.443038        0.000000      0.000000   5.502582   \n",
       "warrendavidson     5.695714        5.185556      5.492222   0.000000   \n",
       "senshelby          0.000000        0.000000      5.502571   0.000000   \n",
       "repkaygranger      0.000000        0.000000      0.000000   0.000000   \n",
       "\n",
       "                repkendrahorn  warrendavidson  senshelby  repkaygranger  \n",
       "senrobportman        0.000000        5.541143   5.582857       0.000000  \n",
       "repterrisewell       5.995000        0.000000   5.290769       0.000000  \n",
       "jeffflake            0.000000        0.000000   0.000000       0.000000  \n",
       "replowenthal         0.000000        0.000000   0.000000       0.000000  \n",
       "staceyplaskett       0.000000        5.721538   0.000000       0.000000  \n",
       "...                       ...             ...        ...            ...  \n",
       "repkendrahorn        5.618359        0.000000   0.000000       0.000000  \n",
       "repcasten            5.326061        0.000000   0.000000       0.000000  \n",
       "warrendavidson       0.000000        5.517688   0.000000       0.000000  \n",
       "senshelby            0.000000        0.000000   5.544500       5.661212  \n",
       "repkaygranger        0.000000        0.000000   5.463871       5.526167  \n",
       "\n",
       "[580 rows x 593 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>senrobportman</th>\n      <th>repterrisewell</th>\n      <th>jeffflake</th>\n      <th>replowenthal</th>\n      <th>staceyplaskett</th>\n      <th>repjoemorelle</th>\n      <th>sanfordbishop</th>\n      <th>repannaeshoo</th>\n      <th>repriggleman</th>\n      <th>congressmangt</th>\n      <th>...</th>\n      <th>repdean</th>\n      <th>usrepkeating</th>\n      <th>replipinski</th>\n      <th>repstevechabot</th>\n      <th>sentomcotton</th>\n      <th>repcasten</th>\n      <th>repkendrahorn</th>\n      <th>warrendavidson</th>\n      <th>senshelby</th>\n      <th>repkaygranger</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>senrobportman</th>\n      <td>5.572385</td>\n      <td>0.000000</td>\n      <td>5.027778</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.594028</td>\n      <td>5.655294</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.541143</td>\n      <td>5.582857</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>repterrisewell</th>\n      <td>0.000000</td>\n      <td>5.497415</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.263119</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.995000</td>\n      <td>0.000000</td>\n      <td>5.290769</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>jeffflake</th>\n      <td>5.413846</td>\n      <td>0.000000</td>\n      <td>5.462290</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>replowenthal</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.477669</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.796296</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>5.818966</td>\n      <td>0.000000</td>\n      <td>5.525806</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>staceyplaskett</th>\n      <td>0.000000</td>\n      <td>5.614857</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.455182</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.721538</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>repkendrahorn</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.618359</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>repcasten</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5.443038</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.502582</td>\n      <td>5.326061</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>warrendavidson</th>\n      <td>5.398366</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.876667</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5.695714</td>\n      <td>5.185556</td>\n      <td>5.492222</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.517688</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>senshelby</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.502571</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.544500</td>\n      <td>5.661212</td>\n    </tr>\n    <tr>\n      <th>repkaygranger</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.463871</td>\n      <td>5.526167</td>\n    </tr>\n  </tbody>\n</table>\n<p>580 rows × 593 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "Text_df_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "francisrooney      0.000000\n",
       "repslotkin         0.000000\n",
       "senbrianschatz     0.000000\n",
       "repdonyoung        0.000000\n",
       "repfinkenauer      0.000000\n",
       "                     ...   \n",
       "buddforcongress    5.735055\n",
       "repmartharoby      5.750750\n",
       "gregformontana     5.769820\n",
       "sen_joemanchin     5.791478\n",
       "reptorressmall     5.905161\n",
       "Name: realdonaldtrump, Length: 580, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "Text_df_sent['realdonaldtrump'].sort_values()"
   ]
  }
 ]
}